{
    "docs": [
        {
            "location": "/",
            "text": "pod-charlesreid1\n\n\nThis repo contains a docker compose file \nfor running the charlesreid1.com site.\n\n\nThe services are:\n\n\n\n\nmediawiki\n\n\napache + php\n\n\nmysql\n\n\nphpmyadmin\n (in progress)\n\n\nnginx + ssl\n (in progress)\n\n\npython\n (in progress)\n\n\ngitea\n (in progress)\n\n\n\n\nRunning\n\n\nSee \nRunning.md\n for info about running this docker pod:\n\n\n\n\nRunning the Docker Pod from Comand Line\n\n\nRunning the Docker Pod as a Startup Service\n\n\nWorkflow for Charlesreid1 Docker Pod Updates\n\n\nRestoring the Docker Pod from Backups\n\n\n\n\nVolumes\n\n\nSee \nVolumes.md\n for info about data and volumes \nused by this docker pod:\n\n\n\n\nPersistent Data Volumes\n\n\nnginx\n\n\nnginx + lets encrypt ssl certificates\n\n\nnginx static content\n\n\nnginx bind-mounted files\n\n\n\n\n\n\nmysql\n\n\nmediawiki\n\n\nmediawiki data volume\n\n\nmediawiki bind-mounted files\n\n\n\n\n\n\ngitea\n\n\ngitea data volume\n\n\ngitea bind-mounted files\n\n\n\n\n\n\npython file server (pyfiles)\n\n\npyfiles directory\n\n\n\n\n\n\n\n\nBackups\n\n\nThere are a number of directories containing utility scripts - these are mostly \ndedicated to creating backups of any non-version-controlled data inside the container.\n\n\nSee \nBackups.md\n for coverage of backup and utility scripts.\n\n\nutils-backups\n - backup utilities (use the scripts below; good for cron jobs)\n\n\nutils-mw\n - mediawiki backup utilities\n\n\nutils-mysql\n mysql backup utilities\n\n\nDomains and Ports\n\n\nSee \nPorts.md\n for info about top-level domain names\nand ports used by this docker pod.\n\n\nThe domains ports document covers:\n\n\n\n\nDomains\n\n\nnginx domain handling\n\n\n\n\n\n\nPorts\n\n\nnginx ports\n\n\nmediawiki/apache ports\n\n\nphpmyadmin ports\n\n\nmysql ports\n\n\ngitea ports\n\n\npython file server ports\n\n\n\n\n\n\n\n\nSecrets\n\n\nSee \nSecrets.md\n for more info about getting secrets like \npasswords and sensitive files into various containers in the pod,\nwithout leaking out the information.\n\n\n\n\nmysql database root password\n\n\nmediawiki mysql database root password\n\n\ngitea secret key and session id\n\n\nnginx ssl certificates\n\n\n\n\nContainer-Specific Configuration Details\n\n\nEach container has a different way of getting\nconfiguration files into the container.\nIn the following documents we cover \nthe specifics of each container.\n\n\n\n\nmediawiki\n\n\napache + php\n\n\nmysql\n\n\nphpmyadmin\n \n\n\nnginx + ssl\n\n\npython\n\n\ngitea\n\n\n\n\nRunning\n\n\nFrom your project directory, start up your application by running:\n\n\n$ docker-compose up\n\n\n\n\nIf you want to rebuild the images (if you changed the Dockerfile),\nuse the \n--build\n flag:\n\n\n$ docker-compose up --build\n\n\n\n\nLinks\n\n\ndocker compose documentation:\n\n\n\n\ngetting started\n\n\nset environment variables in containers\n\n\ndocker secrets\n (nope)",
            "title": "Index"
        },
        {
            "location": "/#pod-charlesreid1",
            "text": "This repo contains a docker compose file \nfor running the charlesreid1.com site.  The services are:   mediawiki  apache + php  mysql  phpmyadmin  (in progress)  nginx + ssl  (in progress)  python  (in progress)  gitea  (in progress)",
            "title": "pod-charlesreid1"
        },
        {
            "location": "/#running",
            "text": "See  Running.md  for info about running this docker pod:   Running the Docker Pod from Comand Line  Running the Docker Pod as a Startup Service  Workflow for Charlesreid1 Docker Pod Updates  Restoring the Docker Pod from Backups",
            "title": "Running"
        },
        {
            "location": "/#volumes",
            "text": "See  Volumes.md  for info about data and volumes \nused by this docker pod:   Persistent Data Volumes  nginx  nginx + lets encrypt ssl certificates  nginx static content  nginx bind-mounted files    mysql  mediawiki  mediawiki data volume  mediawiki bind-mounted files    gitea  gitea data volume  gitea bind-mounted files    python file server (pyfiles)  pyfiles directory",
            "title": "Volumes"
        },
        {
            "location": "/#backups",
            "text": "There are a number of directories containing utility scripts - these are mostly \ndedicated to creating backups of any non-version-controlled data inside the container.  See  Backups.md  for coverage of backup and utility scripts.  utils-backups  - backup utilities (use the scripts below; good for cron jobs)  utils-mw  - mediawiki backup utilities  utils-mysql  mysql backup utilities",
            "title": "Backups"
        },
        {
            "location": "/#domains-and-ports",
            "text": "See  Ports.md  for info about top-level domain names\nand ports used by this docker pod.  The domains ports document covers:   Domains  nginx domain handling    Ports  nginx ports  mediawiki/apache ports  phpmyadmin ports  mysql ports  gitea ports  python file server ports",
            "title": "Domains and Ports"
        },
        {
            "location": "/#secrets",
            "text": "See  Secrets.md  for more info about getting secrets like \npasswords and sensitive files into various containers in the pod,\nwithout leaking out the information.   mysql database root password  mediawiki mysql database root password  gitea secret key and session id  nginx ssl certificates",
            "title": "Secrets"
        },
        {
            "location": "/#container-specific-configuration-details",
            "text": "Each container has a different way of getting\nconfiguration files into the container.\nIn the following documents we cover \nthe specifics of each container.   mediawiki  apache + php  mysql  phpmyadmin    nginx + ssl  python  gitea",
            "title": "Container-Specific Configuration Details"
        },
        {
            "location": "/#running_1",
            "text": "From your project directory, start up your application by running:  $ docker-compose up  If you want to rebuild the images (if you changed the Dockerfile),\nuse the  --build  flag:  $ docker-compose up --build",
            "title": "Running"
        },
        {
            "location": "/#links",
            "text": "docker compose documentation:   getting started  set environment variables in containers  docker secrets  (nope)",
            "title": "Links"
        },
        {
            "location": "/Running/",
            "text": "Running the Charlesreid1 Docker Pod\n\n\nThe charlesreid1.com site runs in a Docker pod.\nUse \ndocker-compose\n to run the pod.\n\n\nThe Docker Compose File\n\n\nThe \ndocker-compose.yml\n file contains all the directives needed\nto run a docker pod of containers that make Charlesreid1.com work.\n\n\nWhy use docker-compose instead of docker? \ndocker-compose is the preferred way to run multiple containers.\n\n\nHuh? Where's docker-compose.yml??\n\n\nInstead of a \ndocker-compose.yml\n file, \nyou'll see a \ndocker-compose.fixme.yml\n file.\nYou need to fix this YML file by hard-coding your \nMYSQL password in the file.\n\n\nSee the steps below.\n\n\n\n\nRunning Charlesreid1 Docker Pod from Command Line\n\n\nWe start by covering how to run the docker pod from the command line.\n\n\nFirst, set the MySQL password using a sed one-liner:\n\n\n$ sed \"s/REPLACEME/YoFooThisIsYourNewPassword/\" docker-compose.fixme.yml > docker-compose.yml\n\n\n\n\nNow you can run the container pod with\n\n\ndocker-compose up       # interactive\ndocker-compose up -d    # detached\n\n\n\n\nor, if you want to rebuild all the containers before running up,\n\n\ndocker-compose up --build\n\n\n\n\nIf you just want to rebuild the containers,\n\n\ndocker-compose build\n\n\n\n\nand this will rebuild the containers from scratch:\n\n\ndocker-compose build --no-cache\n\n\n\n\nWARNING:\n for large, complicated container images,\nthis command can take a very long time.\nUse with care.)\n\n\nYou can restart all containers in a pod using the restart command:\n\n\ndocker-compose restart\n\n\n\n\nWARNING:\n this will \nNOT\n pick up changes to \nDockerfiles or to files that are mounted into the container.\nThis simply restarts the container using the same image \n(in memory) that was previously running, \nwithout\n\ngetting an up-to-date container image.\n\n\n\n\nRunning Charlesreid1 Docker Pod as Startup Service\n\n\nIf you want to run the pod as a startup service,\nsee the dotfiles/debian repository, in the services/\nsubdirectory. You will find a systemd service\nthat will start/stop the docker pod.\n\n\ndockerpod-charlesereid1.service:\n\n\n[Unit]\nDescription=charlesreid1 docker pod\nRequires=docker.service\nAfter=docker.service\n\n[Service]\nRestart=always\nExecStart=/usr/local/bin/docker-compose -f /home/charles/codes/docker/pod-charlesreid1/docker-compose.yml up\nExecStop=/usr/local/bin/docker-compose  -f /home/charles/codes/docker/pod-charlesreid1/docker-compose.yml stop\n\n[Install]\nWantedBy=default.target\n\n\n\n\nNow install the service to \n/etc/systemd/system/dockerpod-charlesreid1.servce\n,\nand activate it:\n\n\nsudo systemctl enable dockerpod-charlesreid1.service\n\n\n\n\nNow you can start/stop the service with:\n\n\nsudo systemctl (start|stop) dockerpod-charlesreid1.service\n\n\n\n\nNOTE: if you need to debug the containers, \nor update any config files copied into the container,\nbe sure and stop the service before doing a \n\ndocker-compose stop\n or a \ndocker-compose up --build\n,\notherwise the pod will continually respawn.\n\n\n\n\nWorkflow for Charlesreid1 Docker Pod Updates\n\n\nThis section covers a workflow if you're updating the docker pod.\n\n\nAs noted abobve, a simple \ndocker-compose restart\n won't pick up\nchanges in Dockerfiles or files mounted into the image, so \nyou often need to stop the containers and restart them after \nrebuilding the container images.\n\n\nHowever, if you update your files (particularly if you add a lot of new \napt packages), it can take a long time to build the containers.\nThis can result in a lot of downtime if you take the containers down\nbefore rebuilding them.\n\n\nTo minimize downtime, use the following workflow:\n\n\n\n\nRun \ndocker-compose build\n to rebuild the images, leaving the pod running (they are not affected)\n\n\nRun \ndocker-compose down\n to bring the pod down\n\n\nRun \ndocker-compose up\n to bring the pod up\n\n\n\n\nIt may take a few seconds to bring the pod down,\nand that will be your total amount of downtime.\n\n\nIf you make a thousand dollars a second and can't afford\nyour site to be down for even a few seconds of downtime, \nhire me and I'll tell you how to do it with \nZERO\n downtime.\n\n\n\n\nRestoring Docker Pod from Backups\n\n\nNow that the pod is running, you probably need to seed it with data.\n\n\nYou will need two mediawiki restore files and two gitea restore files,\neverything else comes from git.charlesreid1.com or github.com\n(this will create a bootstrapping problem if you have no git.charlesreid1.com):\n\n\n\n\nMediaWiki database backup\n\n\nMediaWiki files (images) backup\n\n\nGitea dump zip file\n\n\nGitea avatars zip file\n\n\n\n\nNow you can restore the database as follows:\n\n\n\n\nMySQL database restore scripts for MediaWiki are in \nutils-mysql/\n dir\n\n\nMediaWiki image directory restore scripts are in \nutils-mw/\n dir\n\n\nGitea database and avatars come from backups using scripts in \nutils-gitea/\n dir\n\n\n\n\nmysql restore\n\n\nTo restore a database from a dump:\n\n\ncd utils-mysql/\n./restore_database.sh /path/to/dump/wikidb.sql\n\n\n\n\nThe MySQL container must be running for this to work.\n(You may need to adjust the MySQL container name in the script.)\n\n\nmediawiki restore\n\n\nTo restore the MediaWiki images directory:\n\n\ncd utils-mw/\n./restore_wikifiles.sh /path/to/wikifiles.tar.gz\n\n\n\n\ngitea restore\n\n\nThe gitea container can be restored from a backup as follows:\n\n\ncd utils-gitea/\n./restore_gitea.sh /path/to/gitea-dump.zip /path/to/gitea-avatars.zip",
            "title": "Running the Charlesreid1 Docker Pod"
        },
        {
            "location": "/Running/#running-the-charlesreid1-docker-pod",
            "text": "The charlesreid1.com site runs in a Docker pod.\nUse  docker-compose  to run the pod.",
            "title": "Running the Charlesreid1 Docker Pod"
        },
        {
            "location": "/Running/#the-docker-compose-file",
            "text": "The  docker-compose.yml  file contains all the directives needed\nto run a docker pod of containers that make Charlesreid1.com work.  Why use docker-compose instead of docker? \ndocker-compose is the preferred way to run multiple containers.  Huh? Where's docker-compose.yml??  Instead of a  docker-compose.yml  file, \nyou'll see a  docker-compose.fixme.yml  file.\nYou need to fix this YML file by hard-coding your \nMYSQL password in the file.  See the steps below.",
            "title": "The Docker Compose File"
        },
        {
            "location": "/Running/#running-charlesreid1-docker-pod-from-command-line",
            "text": "We start by covering how to run the docker pod from the command line.  First, set the MySQL password using a sed one-liner:  $ sed \"s/REPLACEME/YoFooThisIsYourNewPassword/\" docker-compose.fixme.yml > docker-compose.yml  Now you can run the container pod with  docker-compose up       # interactive\ndocker-compose up -d    # detached  or, if you want to rebuild all the containers before running up,  docker-compose up --build  If you just want to rebuild the containers,  docker-compose build  and this will rebuild the containers from scratch:  docker-compose build --no-cache  WARNING:  for large, complicated container images,\nthis command can take a very long time.\nUse with care.)  You can restart all containers in a pod using the restart command:  docker-compose restart  WARNING:  this will  NOT  pick up changes to \nDockerfiles or to files that are mounted into the container.\nThis simply restarts the container using the same image \n(in memory) that was previously running,  without \ngetting an up-to-date container image.",
            "title": "Running Charlesreid1 Docker Pod from Command Line"
        },
        {
            "location": "/Running/#running-charlesreid1-docker-pod-as-startup-service",
            "text": "If you want to run the pod as a startup service,\nsee the dotfiles/debian repository, in the services/\nsubdirectory. You will find a systemd service\nthat will start/stop the docker pod.  dockerpod-charlesereid1.service:  [Unit]\nDescription=charlesreid1 docker pod\nRequires=docker.service\nAfter=docker.service\n\n[Service]\nRestart=always\nExecStart=/usr/local/bin/docker-compose -f /home/charles/codes/docker/pod-charlesreid1/docker-compose.yml up\nExecStop=/usr/local/bin/docker-compose  -f /home/charles/codes/docker/pod-charlesreid1/docker-compose.yml stop\n\n[Install]\nWantedBy=default.target  Now install the service to  /etc/systemd/system/dockerpod-charlesreid1.servce ,\nand activate it:  sudo systemctl enable dockerpod-charlesreid1.service  Now you can start/stop the service with:  sudo systemctl (start|stop) dockerpod-charlesreid1.service  NOTE: if you need to debug the containers, \nor update any config files copied into the container,\nbe sure and stop the service before doing a  docker-compose stop  or a  docker-compose up --build ,\notherwise the pod will continually respawn.",
            "title": "Running Charlesreid1 Docker Pod as Startup Service"
        },
        {
            "location": "/Running/#workflow-for-charlesreid1-docker-pod-updates",
            "text": "This section covers a workflow if you're updating the docker pod.  As noted abobve, a simple  docker-compose restart  won't pick up\nchanges in Dockerfiles or files mounted into the image, so \nyou often need to stop the containers and restart them after \nrebuilding the container images.  However, if you update your files (particularly if you add a lot of new \napt packages), it can take a long time to build the containers.\nThis can result in a lot of downtime if you take the containers down\nbefore rebuilding them.  To minimize downtime, use the following workflow:   Run  docker-compose build  to rebuild the images, leaving the pod running (they are not affected)  Run  docker-compose down  to bring the pod down  Run  docker-compose up  to bring the pod up   It may take a few seconds to bring the pod down,\nand that will be your total amount of downtime.  If you make a thousand dollars a second and can't afford\nyour site to be down for even a few seconds of downtime, \nhire me and I'll tell you how to do it with  ZERO  downtime.",
            "title": "Workflow for Charlesreid1 Docker Pod Updates"
        },
        {
            "location": "/Running/#restoring-docker-pod-from-backups",
            "text": "Now that the pod is running, you probably need to seed it with data.  You will need two mediawiki restore files and two gitea restore files,\neverything else comes from git.charlesreid1.com or github.com\n(this will create a bootstrapping problem if you have no git.charlesreid1.com):   MediaWiki database backup  MediaWiki files (images) backup  Gitea dump zip file  Gitea avatars zip file   Now you can restore the database as follows:   MySQL database restore scripts for MediaWiki are in  utils-mysql/  dir  MediaWiki image directory restore scripts are in  utils-mw/  dir  Gitea database and avatars come from backups using scripts in  utils-gitea/  dir",
            "title": "Restoring Docker Pod from Backups"
        },
        {
            "location": "/Running/#mysql-restore",
            "text": "To restore a database from a dump:  cd utils-mysql/\n./restore_database.sh /path/to/dump/wikidb.sql  The MySQL container must be running for this to work.\n(You may need to adjust the MySQL container name in the script.)",
            "title": "mysql restore"
        },
        {
            "location": "/Running/#mediawiki-restore",
            "text": "To restore the MediaWiki images directory:  cd utils-mw/\n./restore_wikifiles.sh /path/to/wikifiles.tar.gz",
            "title": "mediawiki restore"
        },
        {
            "location": "/Running/#gitea-restore",
            "text": "The gitea container can be restored from a backup as follows:  cd utils-gitea/\n./restore_gitea.sh /path/to/gitea-dump.zip /path/to/gitea-avatars.zip",
            "title": "gitea restore"
        },
        {
            "location": "/Volumes/",
            "text": "Volumes\n\n\nPersistent Data Volumes\n\n\ndocker-compose volumes are mostly persistent, but they can\nbe deleted relatively easily.\n\n\nWhen you're using docker-compose, volumes are persistent\nthrough both \ndocker-compose stop\n and \ndocker-compose down\n commands.\n\n\nThe \ndocker-compose down\n command will destroy everything including networks\nand mounted files, while \ndocker-compose stop\n will just stop the containers.\n\n\nDANGER - DANGER - DANGER\n\n\nIf you want to remove the volumes, use \ndocker-compose down -v\n.\n\n\ndocker-compose down -v   # DANGER!!!\n\n\n\n\nTo force removal of the volumes:\n\n\ndocker-compose down -v -f   # DANGER!!!\n\n\n\n\nTo see the current list of docker volumes:\n\n\ndocker volume ls\n\n\n\n\nYou can also interact with the volumes individually\nthis way. Run \ndocker volume\n for help.\n\n\n\n\nnginx\n\n\nThe nginx service does not have any data volumes, \nbut has several static files that are bind-mounted.\nMost importantly, nginx handles the SSL certificates\nfor all subdomains.\n\n\n\n\nnginx + lets encrypt ssl certificates\n\n\nRather than fuss with getting the letsencrypt \ndocker image working, we made SSL certs by hand.\n\n\nSee \ngit.charlesreid1.com/charlesreid1/certbot\n\n\nCertbot will put the SSL certificates into\n\n/etc/letsencrypt/live/example.com\n.\n\n\nWe bind-mount the entire \n/etc/letsencrypt\n directory\ninto the same location in the nginx container \n(see this volumes line in \ndocker-compose.yml\n):\n\n\n      - \"/etc/letsencrypt:/etc/letsencrypt\"\n\n\n\n\nTo renew certificates (every few months), just run the certbot script in the certbot repo.\n\n\nnginx static content\n\n\nThe main site hosted by nginx (charlesreid1.com) is served up \nfrom a directory of static content under version control.\n\n\nThis static content is bind-mounted and lives on the host \n(no data volume is used for nginx).\n\n\nOn the host, static site contents are stored at \n/www/\n \nwith a directory structure and corresponding permissions\nas follows:\n\n\n/www/                                   # <-- owned by regular user\n\n    charlesreid1.blue/                  # <-- owned by regular user\n        charlesreid1.blue-src/          # <-- owned by regular user\n            <pelican files>\n        htdocs/                         # <-- owned by www-data\n            <web site static contents>\n\n    charlesreid1.red/                   # <-- owned by regular user\n        charlesreid1.red-src/           # <-- owned by regular user\n            <pelican files>\n        htdocs/                         # <-- owned by www-data\n            <web site static contents>\n\n    charlesreid1.com/\n        charlesreid1.com-src/\n            <pelican files>\n        htdocs/\n            <web site static contents>\n\n    ...\n\n\n\n\nEach domain has its own directory, in which there is a source directory \n(git repository containing pelican files) and an htdocs directory\n(git repository containing live hosted static content).\n\n\nThese are mounted in the container at the same location.\nSee the volumes section of the nginx container:\n\n\n      - \"/www/charlesreid1.blue/htdocs:/www/charlesreid1.blue/htdocs:ro\"\n      - \"/www/charlesreid1.red/htdocs:/www/charlesreid1.red/htdocs:ro\"\n      - \"/www/charlesreid1.com/htdocs:/www/charlesreid1.com/htdocs:ro\"\n\n\n\n\nThe source and htdocs directories are separate branches of the same repo.\nEach website has (TODO: will have) its own repository.\n\n\nThe \nmaster\n branch contains the source code for that repository,\nmainly pelican files plus html/css/js.\n\n\nThe \npages\n branch contains the static content to be hosted \nby the nginx web server.\n\n\nOwnership makes dealing with this stuff a pain in the ass.\nThe \nhtdocs\n dir must be owned/updated by \nwww-data\n, \nso you need to update the git repo contents as that user:\n\n\nsudo -H -u www-data git pull origin pages\n\n\n\n\nnginx bind-mounted files\n\n\nWe bind-mount a directory \nconf.d\n containing \nnginx configuration files into the container \nat \n/etc/nginx/conf.d\n, which is where nginx\nautomatically looks for and loads configuration \nfiles.\n\n\nThe custom nginx configuration files are split up\nby protocol and subdomain, and can be found \nin the \nd-nginx-charlesreid1\n\nrepository. From the \ndocker-compose.yml\n file\nnginx volumes directive:\n\n\n      - \"./d-nginx-charlesreid1/conf.d:/etc/nginx/conf.d:ro\"\n\n\n\n\nother nginx bind-mounted files\n\n\nThe last remaining nginx file that is bind-mounted into the container\nis \n/etc/localtime\n, which ensures our webserver's timestamps match \nthe host's. In the nginx volumes directive:\n\n\n      - \"/etc/localtime:/etc/localtime:ro\"\n\n\n\n\n\n\nmysql\n\n\nThe MySQL database container is used by MediaWiki \nand stores its data on disk in a data volume.\nInside the conatiner all MySQL data lives at\n\n\n/var/lib/mysql\n\n\n\n\nThis is mapped to a data volume, \nstormy_mysql_data\n.\n\n\nThere is no custom configuration of the MySQL database\nat this time, but to add a custom config file,\nmount it in the container via bind-mounting\nby adding this to the volumes section of \n\ndocker-compose.yml\n:\n\n\n      - \"./d-mysql/krash.mysql.cnf:/etc/mysql/conf.d/krash.mysql.cnf\"\n\n\n\n\n\n\nmediawiki\n\n\nmediawiki data volume\n\n\nThe MediaWiki container hosts all wiki files\nfrom \n/var/www/html\n (in the MediaWiki container).\n\n\nWhen the container is built from the Dockerfile, \nmost of the customized MediaWiki files are copied\ninto the data volume. These include:\n\n\n\n\nLocalSettings.php\n - MediaWiki config file\n\n\nskins/\n directory\n\n\nextensions/\n directory\n\n\n\n\nMediaWiki files are kept under version control in the \n\nd-mediawiki\n\nrepo.\n\n\nThe MediaWiki container uses a data volume called \n\nstormy_mw_data\n, which is mounted at \n/var/www/html\n\ninside the container.\n\n\nThe docker-compose file takes care of creating the data volume.\n\n\nmediawiki bind-mounted files\n\n\n(TODO: ambiguous how skins dir is mounted;\ncopying skins into container in Dockerfile,\nand bind-mounting bootstrap2 at runtime.)\n\n\nMediaWiki skins are kept under version control\nin the \nd-mediawiki\n\nrepo.\n\n\nThe Bootstrap2 MediaWiki skin is bind-mounted into the container\nat \n/var/www/html/skins/Bootstrap2/\n.\n\n\nIf you make changes to the skin or MediaWiki config files,\nupdate the MediaWiki docker image as follows:\n\n\ndocker-compose build\ndocker-compose down\ndocker-compose up\n\n\n\n\n\n\ngitea\n\n\ngitea data volume\n\n\ngitea bind-mounted files\n\n\n\n\npython file server\n\n\npyfiles directory",
            "title": "Volumes"
        },
        {
            "location": "/Volumes/#volumes",
            "text": "",
            "title": "Volumes"
        },
        {
            "location": "/Volumes/#persistent-data-volumes",
            "text": "docker-compose volumes are mostly persistent, but they can\nbe deleted relatively easily.  When you're using docker-compose, volumes are persistent\nthrough both  docker-compose stop  and  docker-compose down  commands.  The  docker-compose down  command will destroy everything including networks\nand mounted files, while  docker-compose stop  will just stop the containers.  DANGER - DANGER - DANGER  If you want to remove the volumes, use  docker-compose down -v .  docker-compose down -v   # DANGER!!!  To force removal of the volumes:  docker-compose down -v -f   # DANGER!!!  To see the current list of docker volumes:  docker volume ls  You can also interact with the volumes individually\nthis way. Run  docker volume  for help.",
            "title": "Persistent Data Volumes"
        },
        {
            "location": "/Volumes/#nginx",
            "text": "The nginx service does not have any data volumes, \nbut has several static files that are bind-mounted.\nMost importantly, nginx handles the SSL certificates\nfor all subdomains.",
            "title": "nginx"
        },
        {
            "location": "/Volumes/#nginx-lets-encrypt-ssl-certificates",
            "text": "Rather than fuss with getting the letsencrypt \ndocker image working, we made SSL certs by hand.  See  git.charlesreid1.com/charlesreid1/certbot  Certbot will put the SSL certificates into /etc/letsencrypt/live/example.com .  We bind-mount the entire  /etc/letsencrypt  directory\ninto the same location in the nginx container \n(see this volumes line in  docker-compose.yml ):        - \"/etc/letsencrypt:/etc/letsencrypt\"  To renew certificates (every few months), just run the certbot script in the certbot repo.",
            "title": "nginx + lets encrypt ssl certificates"
        },
        {
            "location": "/Volumes/#nginx-static-content",
            "text": "The main site hosted by nginx (charlesreid1.com) is served up \nfrom a directory of static content under version control.  This static content is bind-mounted and lives on the host \n(no data volume is used for nginx).  On the host, static site contents are stored at  /www/  \nwith a directory structure and corresponding permissions\nas follows:  /www/                                   # <-- owned by regular user\n\n    charlesreid1.blue/                  # <-- owned by regular user\n        charlesreid1.blue-src/          # <-- owned by regular user\n            <pelican files>\n        htdocs/                         # <-- owned by www-data\n            <web site static contents>\n\n    charlesreid1.red/                   # <-- owned by regular user\n        charlesreid1.red-src/           # <-- owned by regular user\n            <pelican files>\n        htdocs/                         # <-- owned by www-data\n            <web site static contents>\n\n    charlesreid1.com/\n        charlesreid1.com-src/\n            <pelican files>\n        htdocs/\n            <web site static contents>\n\n    ...  Each domain has its own directory, in which there is a source directory \n(git repository containing pelican files) and an htdocs directory\n(git repository containing live hosted static content).  These are mounted in the container at the same location.\nSee the volumes section of the nginx container:        - \"/www/charlesreid1.blue/htdocs:/www/charlesreid1.blue/htdocs:ro\"\n      - \"/www/charlesreid1.red/htdocs:/www/charlesreid1.red/htdocs:ro\"\n      - \"/www/charlesreid1.com/htdocs:/www/charlesreid1.com/htdocs:ro\"  The source and htdocs directories are separate branches of the same repo.\nEach website has (TODO: will have) its own repository.  The  master  branch contains the source code for that repository,\nmainly pelican files plus html/css/js.  The  pages  branch contains the static content to be hosted \nby the nginx web server.  Ownership makes dealing with this stuff a pain in the ass.\nThe  htdocs  dir must be owned/updated by  www-data , \nso you need to update the git repo contents as that user:  sudo -H -u www-data git pull origin pages",
            "title": "nginx static content"
        },
        {
            "location": "/Volumes/#nginx-bind-mounted-files",
            "text": "We bind-mount a directory  conf.d  containing \nnginx configuration files into the container \nat  /etc/nginx/conf.d , which is where nginx\nautomatically looks for and loads configuration \nfiles.  The custom nginx configuration files are split up\nby protocol and subdomain, and can be found \nin the  d-nginx-charlesreid1 \nrepository. From the  docker-compose.yml  file\nnginx volumes directive:        - \"./d-nginx-charlesreid1/conf.d:/etc/nginx/conf.d:ro\"",
            "title": "nginx bind-mounted files"
        },
        {
            "location": "/Volumes/#other-nginx-bind-mounted-files",
            "text": "The last remaining nginx file that is bind-mounted into the container\nis  /etc/localtime , which ensures our webserver's timestamps match \nthe host's. In the nginx volumes directive:        - \"/etc/localtime:/etc/localtime:ro\"",
            "title": "other nginx bind-mounted files"
        },
        {
            "location": "/Volumes/#mysql",
            "text": "The MySQL database container is used by MediaWiki \nand stores its data on disk in a data volume.\nInside the conatiner all MySQL data lives at  /var/lib/mysql  This is mapped to a data volume,  stormy_mysql_data .  There is no custom configuration of the MySQL database\nat this time, but to add a custom config file,\nmount it in the container via bind-mounting\nby adding this to the volumes section of  docker-compose.yml :        - \"./d-mysql/krash.mysql.cnf:/etc/mysql/conf.d/krash.mysql.cnf\"",
            "title": "mysql"
        },
        {
            "location": "/Volumes/#mediawiki",
            "text": "",
            "title": "mediawiki"
        },
        {
            "location": "/Volumes/#mediawiki-data-volume",
            "text": "The MediaWiki container hosts all wiki files\nfrom  /var/www/html  (in the MediaWiki container).  When the container is built from the Dockerfile, \nmost of the customized MediaWiki files are copied\ninto the data volume. These include:   LocalSettings.php  - MediaWiki config file  skins/  directory  extensions/  directory   MediaWiki files are kept under version control in the  d-mediawiki \nrepo.  The MediaWiki container uses a data volume called  stormy_mw_data , which is mounted at  /var/www/html \ninside the container.  The docker-compose file takes care of creating the data volume.",
            "title": "mediawiki data volume"
        },
        {
            "location": "/Volumes/#mediawiki-bind-mounted-files",
            "text": "(TODO: ambiguous how skins dir is mounted;\ncopying skins into container in Dockerfile,\nand bind-mounting bootstrap2 at runtime.)  MediaWiki skins are kept under version control\nin the  d-mediawiki \nrepo.  The Bootstrap2 MediaWiki skin is bind-mounted into the container\nat  /var/www/html/skins/Bootstrap2/ .  If you make changes to the skin or MediaWiki config files,\nupdate the MediaWiki docker image as follows:  docker-compose build\ndocker-compose down\ndocker-compose up",
            "title": "mediawiki bind-mounted files"
        },
        {
            "location": "/Volumes/#gitea",
            "text": "",
            "title": "gitea"
        },
        {
            "location": "/Volumes/#gitea-data-volume",
            "text": "",
            "title": "gitea data volume"
        },
        {
            "location": "/Volumes/#gitea-bind-mounted-files",
            "text": "",
            "title": "gitea bind-mounted files"
        },
        {
            "location": "/Volumes/#python-file-server",
            "text": "",
            "title": "python file server"
        },
        {
            "location": "/Volumes/#pyfiles-directory",
            "text": "",
            "title": "pyfiles directory"
        },
        {
            "location": "/Backups/",
            "text": "Backups\n\n\nKrash Seed\n\n\nBy competely containerizing charlesreid1.com,\nall of the static files for running programs\ncome from docker container images, \nand all configuration files \ncome from git repositories under version control at\n\ngit.charlesreid1.com/docker\n.\n\n\nThat just leaves the core data for each service,\nwhich is what the backup and restore scripts handle.\nThis service data consists of the following:\n\n\n\n\nMediaWiki MySQL database dump (.sql)\n\n\nMediaWiki images directory (.tar.gz)\n\n\nGitea repository dump (.zip)\n\n\nGitea avatar images (.zip)\n\n\n\n\nThese four files form a \"krash seed\" for charlesreid1.com.\n\n\nMySQL Backup/Restore Scripts\n\n\nTo create a MySQL backup, use the \nutils-mysql/dump_database.sh\n script.\n\n\ndump_database.sh script:\nDump a database to an .sql file \nfrom the stormy_mysql container.\n\n       ./dump_database.sh <sql-dump-file>\n\nExample:\n\n       ./dump_database.sh /path/to/wikidb_dump.sql\n\n\n\n\n\nMediaWiki Backup/Restore Scripts\n\n\nbackup_wikifiles.sh script:\nCreate a tar file containing wiki files\nfrom the stormy_mw container\n\n       ./backup_wikifiles.sh <tar-file>\n\nExample:\n\n       ./backup_wikifiles.sh /path/to/wikifiles.tar.gz\n\n\n\n\nGitea Backup/Restore Scripts\n\n\nUtilities\n\n\nUtilities are kept in the \nutils-*\n folders.\n\n\nMySQL Utilities\n\n\nMediaWiki Utilities\n\n\nMySQL Utilities",
            "title": "Backups (TODO)"
        },
        {
            "location": "/Backups/#backups",
            "text": "",
            "title": "Backups"
        },
        {
            "location": "/Backups/#krash-seed",
            "text": "By competely containerizing charlesreid1.com,\nall of the static files for running programs\ncome from docker container images, \nand all configuration files \ncome from git repositories under version control at git.charlesreid1.com/docker .  That just leaves the core data for each service,\nwhich is what the backup and restore scripts handle.\nThis service data consists of the following:   MediaWiki MySQL database dump (.sql)  MediaWiki images directory (.tar.gz)  Gitea repository dump (.zip)  Gitea avatar images (.zip)   These four files form a \"krash seed\" for charlesreid1.com.",
            "title": "Krash Seed"
        },
        {
            "location": "/Backups/#mysql-backuprestore-scripts",
            "text": "To create a MySQL backup, use the  utils-mysql/dump_database.sh  script.  dump_database.sh script:\nDump a database to an .sql file \nfrom the stormy_mysql container.\n\n       ./dump_database.sh <sql-dump-file>\n\nExample:\n\n       ./dump_database.sh /path/to/wikidb_dump.sql",
            "title": "MySQL Backup/Restore Scripts"
        },
        {
            "location": "/Backups/#mediawiki-backuprestore-scripts",
            "text": "backup_wikifiles.sh script:\nCreate a tar file containing wiki files\nfrom the stormy_mw container\n\n       ./backup_wikifiles.sh <tar-file>\n\nExample:\n\n       ./backup_wikifiles.sh /path/to/wikifiles.tar.gz",
            "title": "MediaWiki Backup/Restore Scripts"
        },
        {
            "location": "/Backups/#gitea-backuprestore-scripts",
            "text": "",
            "title": "Gitea Backup/Restore Scripts"
        },
        {
            "location": "/Backups/#utilities",
            "text": "Utilities are kept in the  utils-*  folders.",
            "title": "Utilities"
        },
        {
            "location": "/Backups/#mysql-utilities",
            "text": "",
            "title": "MySQL Utilities"
        },
        {
            "location": "/Backups/#mediawiki-utilities",
            "text": "",
            "title": "MediaWiki Utilities"
        },
        {
            "location": "/Backups/#mysql-utilities_1",
            "text": "",
            "title": "MySQL Utilities"
        },
        {
            "location": "/Ports/",
            "text": "Domains and Ports\n\n\nDomains\n\n\nThere are three domains pointing to this server:\n\n\ncharlesreid1.com\ncharlesreid1.red\ncharlesreid1.blue\n\n\n\n\nThese are pointing to the server's IP address\nusing an A NAME DNS record.\n\n\nThere are also various subdomains set up\n(www, git, files), all pointing to the \nsame location.\n\n\nnginx domain handling\n\n\nNginx handles all of the domains by specifying \na different \ndomain_name\n in each \nserver{}\n block\nof the nginx config files.\n\n\nFor example:\n\n\nserver {\n    listen 80;\n    listen [::]:80;\n    server_name charlesreid1.com;\n    ...\n}\n\nserver {\n    listen 80;\n    listen [::]:80;\n    server_name charlesreid1.blue;\n    ...\n}\n\nserver {\n    listen 80;\n    listen [::]:80;\n    server_name charlesreid1.red;\n    ...\n}\n\n\n\n\nSee the \nconf.d\n dir of\n\nd-nginx-charlesreid1\n.\n\n\nWe will cover this in the nginx ports section,\nbut all http urls are redirected to https urls.\n\n\nPorts\n\n\nnginx ports\n\n\nAlso see \nnginx service\n.\n\n\nNginx has two main public-facing ports:\nport 80 (HTTP) and port 443 (HTTPS).\n\n\nAll requests to \nhttp://\n urls go to port 80,\nand all requests to \nhttps://\n urls go to port 443.\n\n\nThe server will automatically redirect all \nrequests to port 80 to port 443, turning all\nhttp requests into https requests.\n\n\nNginx also exposes port 3000 and forwards it\nalong to \ngit.charlesreid1.com\n. This is for \nlegacy reasons.\n\n\nTo work with MediaWiki, nginx must implement \nrewrite rules: nginx listens for requests going \nto wiki URLs (prefixed with \n/w/\n or \n/wiki\n)\nand proxies those to the correct container.\n\n\nmediawiki/apache ports\n\n\nAlso see \nmediawiki service\n\nand \napache/php service\n.\n\n\nThe MediaWiki server runs on a PHP and Apache stack.\nInside the MediaWiki container, Apache listens on \nport 8989. This port only connects to the nginx container,\nso nginx is the only service that can connect to MediaWiki,\nand only over port 8989.\n\n\nThis nginx-apache connection is not encrypted \nbecause it happens on the same machine. \n\n\nWhen the user connects to the wiki, for example at the url\n\n\nhttps://charlesreid1.com/wiki/Nmap\n\n\n\n\nthe user's connection is with the nginx server.\nThe session is an https session happening over port 443\nand signed by nginx's certificates.\n\n\nIf the user goes to \n\n\nhttp://charlesreid1.com/wiki/Nmap\n\n\n\n\non port 80, this is rewritten to\n\n\nhttps://charlesreid1.com/wiki/Nmap\n\n\n\n\non port 443. In nginx, this is done with a 301:\n\n\nserver {\n    listen 80;\n    listen [::]:80;\n    server_name charlesreid1.com;\n    location / {\n        return 301 https://charlesreid1.com$request_uri;\n    }\n}\n\n\n\n\nNote that nginx plays the role of a central dispatcher \nin the charlesreid1 pod - all containers connect to\nnginx and only nginx, while nginx exposes each container \nto the outside world via requests for various subdomains \nbeing redirected to different ports.\n\n\nphpmyadmin ports\n\n\nAlso see \nphpmyadmin service\n.\n\n\nphpMyAdmin provides a web interface for MySQL databases.\n\n\nThis follows a similar pattern to the MediaWiki Apache container:\n\n\n\n\nThe phpMyAdmin container is connected to the MySQL container\n    via the docker network created by the \ndocker-compose\n command\n    (no container links needed)\n\n\nThe phpMyAdmin container runs an HTTP web interface,\n    and listens only for incoming requests from the local \n    network. Requests to phpMyAdmin are reverse-proxied \n    by the nginx container in this pod.\n\n\nBecause phpMyAdmin is not a heavily-used tool in \n    daily tasks, and because it provides access to \n    sensitive data and operations, it should be \n    completely disabled from public access unless\n    needed.\n\n\n\n\nTo control access to phpMyAdmin, \nconfigure the \nnginx service\n\nto whitelist certain IPs to access\nphpMyAdmin (or shut off all access).\n\n\nmysql ports\n\n\nAlso see \nmysql service\n.\n\n\nThe MySQL container listens on port 3306 by default.\nThe container is only bound to the MediaWiki container, \nso MediaWiki is the only service that can access MySQL.\n\n\ngitea ports\n\n\nAlso see \ngitea service\n.\n\n\nRequests for the subdomain \ngit.charlesreid1.com\n \nare redirected to port 3000 on the docker internal\ncontainer network, where gitea is listening.\n\n\nLike the MediaWiki and phpMyAdmin containers, this follows\nthe same reverse proxy pattern:\n\n\n\n\nThe nginx service handles front-end requests and \n    reverse proxies those rquests to gitea over the \n    internal docker container network.\n\n\nGitea listens to port 3000 and is bound to the \n    local docker network only.\n\n\nGitea does not implement HTTP on the back end;\n    nginx handles HTTPS with client on the front end.\n\n\n\n\npython file server ports\n\n\nAlso see \npython files service\n.\n\n\nWe have a simple, lightweight Python HTTP server\nthat's run in a Docker container via the following\ncommand:\n\n\npython -m http.server -b <bind-address> 8080\n\n\n\n\nThis works because Python provides a built-in HTTP server\nthat, if no index.html file is present, will provide a \ndirectory listing. This is as simple as it gets,\nas far as file servers go.\n\n\nThis follows the same reverse proxy pattern:\n\n\n\n\nPython HTTP server listens for incoming requests\n    on the Docker network only. Client requests are \n    reverse proxied by nginx on the front end.\n\n\nThe server does not handle HTTPS, this is also \n    handled by the nginx container on the frontend.\n\n\nThe bind address and port of the Python HTTP server\n    are set in the command line. The \n<bind-address>\n\n    should be set to the name of the docker container image\n    (\nstormy_files\n).\n\n\n\n\npython -m http.server -b stormy_files 8080\n\n\n\n\nThis listens on port 8080 inside the \npython file server container \nstormy_files\n.\n\n\nThe nginx server reverse-proxies requests for \n\nhttps://files.charlesreid1.com\n\nand forwards them to the container.\n\n\nNote: this container can be expanded to a container\nthat serves multiple directories on multilpe ports\nby using twisted. See the \n\nd-python-helium\n\nrepository for an example.",
            "title": "Domains and Ports"
        },
        {
            "location": "/Ports/#domains-and-ports",
            "text": "",
            "title": "Domains and Ports"
        },
        {
            "location": "/Ports/#domains",
            "text": "There are three domains pointing to this server:  charlesreid1.com\ncharlesreid1.red\ncharlesreid1.blue  These are pointing to the server's IP address\nusing an A NAME DNS record.  There are also various subdomains set up\n(www, git, files), all pointing to the \nsame location.",
            "title": "Domains"
        },
        {
            "location": "/Ports/#nginx-domain-handling",
            "text": "Nginx handles all of the domains by specifying \na different  domain_name  in each  server{}  block\nof the nginx config files.  For example:  server {\n    listen 80;\n    listen [::]:80;\n    server_name charlesreid1.com;\n    ...\n}\n\nserver {\n    listen 80;\n    listen [::]:80;\n    server_name charlesreid1.blue;\n    ...\n}\n\nserver {\n    listen 80;\n    listen [::]:80;\n    server_name charlesreid1.red;\n    ...\n}  See the  conf.d  dir of d-nginx-charlesreid1 .  We will cover this in the nginx ports section,\nbut all http urls are redirected to https urls.",
            "title": "nginx domain handling"
        },
        {
            "location": "/Ports/#ports",
            "text": "",
            "title": "Ports"
        },
        {
            "location": "/Ports/#nginx-ports",
            "text": "Also see  nginx service .  Nginx has two main public-facing ports:\nport 80 (HTTP) and port 443 (HTTPS).  All requests to  http://  urls go to port 80,\nand all requests to  https://  urls go to port 443.  The server will automatically redirect all \nrequests to port 80 to port 443, turning all\nhttp requests into https requests.  Nginx also exposes port 3000 and forwards it\nalong to  git.charlesreid1.com . This is for \nlegacy reasons.  To work with MediaWiki, nginx must implement \nrewrite rules: nginx listens for requests going \nto wiki URLs (prefixed with  /w/  or  /wiki )\nand proxies those to the correct container.",
            "title": "nginx ports"
        },
        {
            "location": "/Ports/#mediawikiapache-ports",
            "text": "Also see  mediawiki service \nand  apache/php service .  The MediaWiki server runs on a PHP and Apache stack.\nInside the MediaWiki container, Apache listens on \nport 8989. This port only connects to the nginx container,\nso nginx is the only service that can connect to MediaWiki,\nand only over port 8989.  This nginx-apache connection is not encrypted \nbecause it happens on the same machine.   When the user connects to the wiki, for example at the url  https://charlesreid1.com/wiki/Nmap  the user's connection is with the nginx server.\nThe session is an https session happening over port 443\nand signed by nginx's certificates.  If the user goes to   http://charlesreid1.com/wiki/Nmap  on port 80, this is rewritten to  https://charlesreid1.com/wiki/Nmap  on port 443. In nginx, this is done with a 301:  server {\n    listen 80;\n    listen [::]:80;\n    server_name charlesreid1.com;\n    location / {\n        return 301 https://charlesreid1.com$request_uri;\n    }\n}  Note that nginx plays the role of a central dispatcher \nin the charlesreid1 pod - all containers connect to\nnginx and only nginx, while nginx exposes each container \nto the outside world via requests for various subdomains \nbeing redirected to different ports.",
            "title": "mediawiki/apache ports"
        },
        {
            "location": "/Ports/#phpmyadmin-ports",
            "text": "Also see  phpmyadmin service .  phpMyAdmin provides a web interface for MySQL databases.  This follows a similar pattern to the MediaWiki Apache container:   The phpMyAdmin container is connected to the MySQL container\n    via the docker network created by the  docker-compose  command\n    (no container links needed)  The phpMyAdmin container runs an HTTP web interface,\n    and listens only for incoming requests from the local \n    network. Requests to phpMyAdmin are reverse-proxied \n    by the nginx container in this pod.  Because phpMyAdmin is not a heavily-used tool in \n    daily tasks, and because it provides access to \n    sensitive data and operations, it should be \n    completely disabled from public access unless\n    needed.   To control access to phpMyAdmin, \nconfigure the  nginx service \nto whitelist certain IPs to access\nphpMyAdmin (or shut off all access).",
            "title": "phpmyadmin ports"
        },
        {
            "location": "/Ports/#mysql-ports",
            "text": "Also see  mysql service .  The MySQL container listens on port 3306 by default.\nThe container is only bound to the MediaWiki container, \nso MediaWiki is the only service that can access MySQL.",
            "title": "mysql ports"
        },
        {
            "location": "/Ports/#gitea-ports",
            "text": "Also see  gitea service .  Requests for the subdomain  git.charlesreid1.com  \nare redirected to port 3000 on the docker internal\ncontainer network, where gitea is listening.  Like the MediaWiki and phpMyAdmin containers, this follows\nthe same reverse proxy pattern:   The nginx service handles front-end requests and \n    reverse proxies those rquests to gitea over the \n    internal docker container network.  Gitea listens to port 3000 and is bound to the \n    local docker network only.  Gitea does not implement HTTP on the back end;\n    nginx handles HTTPS with client on the front end.",
            "title": "gitea ports"
        },
        {
            "location": "/Ports/#python-file-server-ports",
            "text": "Also see  python files service .  We have a simple, lightweight Python HTTP server\nthat's run in a Docker container via the following\ncommand:  python -m http.server -b <bind-address> 8080  This works because Python provides a built-in HTTP server\nthat, if no index.html file is present, will provide a \ndirectory listing. This is as simple as it gets,\nas far as file servers go.  This follows the same reverse proxy pattern:   Python HTTP server listens for incoming requests\n    on the Docker network only. Client requests are \n    reverse proxied by nginx on the front end.  The server does not handle HTTPS, this is also \n    handled by the nginx container on the frontend.  The bind address and port of the Python HTTP server\n    are set in the command line. The  <bind-address> \n    should be set to the name of the docker container image\n    ( stormy_files ).   python -m http.server -b stormy_files 8080  This listens on port 8080 inside the \npython file server container  stormy_files .  The nginx server reverse-proxies requests for  https://files.charlesreid1.com \nand forwards them to the container.  Note: this container can be expanded to a container\nthat serves multiple directories on multilpe ports\nby using twisted. See the  d-python-helium \nrepository for an example.",
            "title": "python file server ports"
        },
        {
            "location": "/Secrets/",
            "text": "Secrets\n\n\nMySQL Password\n\n\nThe MySQL password has to get into the MySQL \nand MediaWiki containers. To do this, we \nhard-code the MySQL password as an environment\nvariable in \ndocker-compose.yml\n.\n\n\nThe file \ndocker-compose.fixme.yml\n contains \nthe placeholder \nREPLACEME\n where the MySQL \npassword goes. \n\n\nTo create a \ndocker-compose.yml\n \nfrom \ndocker-compose.fixme.yml\n:\n\n\n$ sed \"s/REPLACEME/YoFooThisIsYourNewPassword/\" docker-compose.fixme.yml > docker-compose.yml\n\n\n\n\nGreat if you hard-code the password, but - \nwasn't that the whole thing \nwe were trying to avoid?\n\n\nPut the password into a file istead, \nthen grab the password from that file\nand do a find/replace on the docker \ncompose file:\n\n\n$ cat root.password\nmysecretpassword\n\n$ sed \"s/REPLACEME/`cat root.password`/\" docker-compose.fixme.yml > docker-compose.yml\n\n\n\n\nThe \ndocker-compose.yml\n file and \nroot.password\n files are both ignored \nby version control.\n\n\nNginx SSL Certificates\n\n\nThe other secrets we need to get into the container are\nthe SSL certificates for the nginx container.\n\n\nTo generate the SSL certificates using Let's Encrypt,\nuse the script in the \ncertbot\n\ndirectory. These will be stored on the host machine\nat \n/etc/letsencrypt/live/example.com/*\n.\n\n\nTo mount the certificates in the directory,\nwe bind-mount the entire \n/etc/letsencrypt/\n directory\ninto the container with the following line \nin the docker-compose file:\n\n\nservices:\n  ...\n  stormy_nginx:\n    ...\n    volumes:\n      - \"/etc/letsencrypt:/etc/letsencrypt\"\n    ...\n\n\n\n\nMeanwhile, in the nginx configuration file \nthat's mounted into the container, we have\nthe following in the SSL server blocks\n(see \ndocker/d-nginx-charlesreid1\n):\n\n\nserver {\n    # https://charlesreid1.com\n    listen 443;\n    listen [::]:443;\n    server_name charlesreid1.com;\n\n    ssl on;\n    ssl_certificate /etc/letsencrypt/live/charlesreid1.com/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/charlesreid1.com/privkey.pem;\n    include /etc/letsencrypt/options-ssl-nginx.conf;\n\n    ...\n}",
            "title": "Secrets"
        },
        {
            "location": "/Secrets/#secrets",
            "text": "",
            "title": "Secrets"
        },
        {
            "location": "/Secrets/#mysql-password",
            "text": "The MySQL password has to get into the MySQL \nand MediaWiki containers. To do this, we \nhard-code the MySQL password as an environment\nvariable in  docker-compose.yml .  The file  docker-compose.fixme.yml  contains \nthe placeholder  REPLACEME  where the MySQL \npassword goes.   To create a  docker-compose.yml  \nfrom  docker-compose.fixme.yml :  $ sed \"s/REPLACEME/YoFooThisIsYourNewPassword/\" docker-compose.fixme.yml > docker-compose.yml  Great if you hard-code the password, but - \nwasn't that the whole thing \nwe were trying to avoid?  Put the password into a file istead, \nthen grab the password from that file\nand do a find/replace on the docker \ncompose file:  $ cat root.password\nmysecretpassword\n\n$ sed \"s/REPLACEME/`cat root.password`/\" docker-compose.fixme.yml > docker-compose.yml  The  docker-compose.yml  file and  root.password  files are both ignored \nby version control.",
            "title": "MySQL Password"
        },
        {
            "location": "/Secrets/#nginx-ssl-certificates",
            "text": "The other secrets we need to get into the container are\nthe SSL certificates for the nginx container.  To generate the SSL certificates using Let's Encrypt,\nuse the script in the  certbot \ndirectory. These will be stored on the host machine\nat  /etc/letsencrypt/live/example.com/* .  To mount the certificates in the directory,\nwe bind-mount the entire  /etc/letsencrypt/  directory\ninto the container with the following line \nin the docker-compose file:  services:\n  ...\n  stormy_nginx:\n    ...\n    volumes:\n      - \"/etc/letsencrypt:/etc/letsencrypt\"\n    ...  Meanwhile, in the nginx configuration file \nthat's mounted into the container, we have\nthe following in the SSL server blocks\n(see  docker/d-nginx-charlesreid1 ):  server {\n    # https://charlesreid1.com\n    listen 443;\n    listen [::]:443;\n    server_name charlesreid1.com;\n\n    ssl on;\n    ssl_certificate /etc/letsencrypt/live/charlesreid1.com/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/charlesreid1.com/privkey.pem;\n    include /etc/letsencrypt/options-ssl-nginx.conf;\n\n    ...\n}",
            "title": "Nginx SSL Certificates"
        },
        {
            "location": "/Service_mediawiki/",
            "text": "MediaWiki Configuration Details\n\n\nThis describes the container-specific\ndetails of the MediaWiki part of the \nApache-MediaWiki container.\n\n\nAlso see \nApache + PHP\n.\n\n\nThe Container\n\n\nThis is based on a MediaWiki container image\nthat runs MediaWiki, PHP, and Apache all in one \ncontainer.\n\n\nThe Apache server is reverse-proxied by nginx \nin the final pod configuration.\n\n\nConfiguration Files and Folders\n\n\nTo set up the MediaWiki container,\nwe have to copy in the following files:\n\n\n\n\nOne configuration file \nLocalSettings.php\n\n\nTwo directories:\n\n\nextensions/\n\n\nskins/\n\n\n\n\n\n\n\n\nBoth \nLocalSettings.php\n and \nskins/\n are \nunder version control.\n\n\nThe \nextensions/\n directory is assembled\nfrom git repositories directly,\nand so is not under version control.\n\n\nWhere Does Stuff Live?\n\n\nThe \nLocalSettings.php\n file and \nskins/\n folder\nlive in the \nd-mediawiki\n submodule\n(see \ndocker/d-mediawiki\n\non git.charlesreid1.com),\nin the \ncharlesreid1-config\n\nsub-submodule (see \nwiki/charlesreid1-config\n\non git.charlesreid1.com),\nin the \nmediawiki/\n directory.\n\n\nThat's also where the \nextensions/\n\ndirectory goes. There is also \na script there called \nbuild_extensions_dir.sh\n\nto clone copies of each MediaWiki extension.\n\n\nInside the MediaWiki container,\nthe live HTML directory is at \n\n/var/www/html/\n. That is where\n\nLocalSettings.php\n, \nskins/\n, and \nextensions/\n\nlive in the container.\n\n\nThe \n/var/www/html/\n directory is\nmarked as a \nVOLUME\n in the Dockerfile\nand is the mount point for a\ndocker data volume, \nstormy_mediawiki_data\n.\n\n\nSee \nwiki/charlesreid1-config\n\non git.charlesreid1.com.\n\n\nGetting Stuff Into The Container\n\n\nThe configuration files mentioned above\n(LocalSettings, skins, and extensions)\nmust be coiped into the container at build time.\n\n\nThis is done in the MediaWiki Dockerfile - \nsee \nd-mediawiki\n.\n\n\nWhy don't we bind-mount them into the container?\nWe will have problems mounting files to a directory\nthat is itself a mount point. Since \n/var/www/html/\n\nis a mount point for the MediaWiki container's data volume,\nto keep the wiki's files persistent, \nwe can't also bind-mount files at \n\n/var/www/html/.\n\n\nAdditionally, we have to change the permissions of \n\nLocalSettings.pp\n to 600 and change the ownership \nof all files in \n/var/www/html/\n to \nwww-data:www-data\n,\nthe Apache web server user, so that it can \nserve up the wiki.\n\n\nLocalSettings.php\n is copied into the container\nat \n/var/www/html/LocalSettings.php\n.\n\n\nskins/\n is copied into the container at \n\n/var/www/html/skins/\n (we use our own\ncustomized theme, in the Bootstrap2 directory).\n\n\nextensions/\n is copied into the container\nat \n/var/www/html/extensions/\n \n(make sure you run \nbuild_extensions_dir.sh\n first!).\n\n\nbuild_extensions_dir.sh\n\n\nEnabling MediaWiki Math\n\n\nNote that we have one last task to complete,\nand that is enabling the math extensions so that \nwe can add formulas to our wiki.\n\n\nTo do this, we have to add the following aptitude\npackages to an \napt-get install\n command in the \nDockerfile:\n\n\nRUN apt-get update && \\\n    apt-get install -y build-essential \\\n            dvipng \\\n            ocaml \\\n            ghostscript \\\n            imagemagick \\\n            texlive-latex-base \\\n            texlive-latex-extra \\\n            texlive-fonts-recommended \\\n            texlive-lang-greek \\\n            texlive-latex-recommended\n\n\n\n\n(Note: ocaml is a language required to make\n\ntexvc\n, covered below.)\n\n\nNext, we need to shim a make command \ninto the container's entrypoint command,\nbefore we run the Apache web server.\n\n\nTo enable equations and math, we need to make\na utility called \ntexvc\n by running \nmake\n in the \nMath extension directory. \n\n\nWe modify the \nCMD\n directive in the Dockerfile,\nwhich normally runs \napache2-foreground\n \nin the stock MediaWiki container.\n\n\nChange the original \nCMD\n from this:\n\n\nCMD apache2-foreground\n\n\n\n\nto this:\n\n\nCMD cd /var/www/html/extensions/Math/math && make && apache2-foreground\n\n\n\n\nUpdating Skin or LocalSettings.php\n\n\nNote that if you update the MediaWiki skin \nor the LocalSettings.php file, \nyou will need to rebuild the container\nand restart it.\n\n\n(It's a pain in the ass, but hard to avoid.)\n\n\nAlternatively, you can use \ndocker cp\n to\ncopy a new \nLocalSettings.php\n or \nskins directory into the running\nMediaWiki container. These changes\nwill be reflected immediately in the \nwiki interface.\n\n\n(Be careful with this method!!!)\n\n\nBest of all possible worlds:\nyour \nLocalSettings.php\n\nand \nskins/\n directory\nis under version control,\nas in \nwiki/charlesreid1-config\n\non git.charlesreid1.com,\nand can be updated with a \ngit push or git pull.\n\n\n(This is not currently how\nit is structured, as the \nskin and LocalSettings.php\nfiles are not under version \ncontrol in the container. \nThis would be difficult for \nthe same reason that it is \ndifficult to bind-mount\na file directly into \n\n/var/www/html\n - because\nit is also difficult \nto have a particular \nfile under version control\nwhen there are a \nlarge number of other files\nin that directory.)\n\n\nA Way Out? A Path Forward? A Glimmer of Hope?\n\n\nHow might we fix this nested, nightarish mess?\n\n\nA couple of things have to happen:\n\n\n\n\n\n\nDocker needs to provide better control over user ownership\n    and file permissions for bind-mounted directories.\n    There are some really ugly, hacky shims that are \n    required because the user permissions of everything\n    are buggered from the start.\n\n\n\n\n\n\nMediaWiki needs to put user configuration files\n    into a configuration folder. For example, \n    \nnginx\n looks in a folder \n/etc/nginx/\n for \n    any and all configuration files. This allows\n    bind-mounting a configuration directory \n    to \n/etc/nginx/\n without complication.\n    Unfortunately, MediaWiki mixes site-specific user files\n    with generic, common-across-all-MediaWikis\n    php files, making it difficult to version-control\n    site-specific user files.\n\n\n\n\n\n\nUtilities\n\n\nThere are utilities for MediaWiki in \nutils-mw\n:\n\n\n\n\nbackup_wikifiles.sh\n - back up wiki image files to a tarball\n\n\nrestore_wikifiles.sh\n - restore backed up image files from a tarball\n\n\nupdate_wikidb.sh\n - one-time script to update the wiki database after a version bump",
            "title": "Pod Service: MediaWiki"
        },
        {
            "location": "/Service_mediawiki/#mediawiki-configuration-details",
            "text": "This describes the container-specific\ndetails of the MediaWiki part of the \nApache-MediaWiki container.  Also see  Apache + PHP .",
            "title": "MediaWiki Configuration Details"
        },
        {
            "location": "/Service_mediawiki/#the-container",
            "text": "This is based on a MediaWiki container image\nthat runs MediaWiki, PHP, and Apache all in one \ncontainer.  The Apache server is reverse-proxied by nginx \nin the final pod configuration.",
            "title": "The Container"
        },
        {
            "location": "/Service_mediawiki/#configuration-files-and-folders",
            "text": "To set up the MediaWiki container,\nwe have to copy in the following files:   One configuration file  LocalSettings.php  Two directories:  extensions/  skins/     Both  LocalSettings.php  and  skins/  are \nunder version control.  The  extensions/  directory is assembled\nfrom git repositories directly,\nand so is not under version control.",
            "title": "Configuration Files and Folders"
        },
        {
            "location": "/Service_mediawiki/#where-does-stuff-live",
            "text": "The  LocalSettings.php  file and  skins/  folder\nlive in the  d-mediawiki  submodule\n(see  docker/d-mediawiki \non git.charlesreid1.com),\nin the  charlesreid1-config \nsub-submodule (see  wiki/charlesreid1-config \non git.charlesreid1.com),\nin the  mediawiki/  directory.  That's also where the  extensions/ \ndirectory goes. There is also \na script there called  build_extensions_dir.sh \nto clone copies of each MediaWiki extension.  Inside the MediaWiki container,\nthe live HTML directory is at  /var/www/html/ . That is where LocalSettings.php ,  skins/ , and  extensions/ \nlive in the container.  The  /var/www/html/  directory is\nmarked as a  VOLUME  in the Dockerfile\nand is the mount point for a\ndocker data volume,  stormy_mediawiki_data .  See  wiki/charlesreid1-config \non git.charlesreid1.com.",
            "title": "Where Does Stuff Live?"
        },
        {
            "location": "/Service_mediawiki/#getting-stuff-into-the-container",
            "text": "The configuration files mentioned above\n(LocalSettings, skins, and extensions)\nmust be coiped into the container at build time.  This is done in the MediaWiki Dockerfile - \nsee  d-mediawiki .  Why don't we bind-mount them into the container?\nWe will have problems mounting files to a directory\nthat is itself a mount point. Since  /var/www/html/ \nis a mount point for the MediaWiki container's data volume,\nto keep the wiki's files persistent, \nwe can't also bind-mount files at  /var/www/html/.  Additionally, we have to change the permissions of  LocalSettings.pp  to 600 and change the ownership \nof all files in  /var/www/html/  to  www-data:www-data ,\nthe Apache web server user, so that it can \nserve up the wiki.  LocalSettings.php  is copied into the container\nat  /var/www/html/LocalSettings.php .  skins/  is copied into the container at  /var/www/html/skins/  (we use our own\ncustomized theme, in the Bootstrap2 directory).  extensions/  is copied into the container\nat  /var/www/html/extensions/  \n(make sure you run  build_extensions_dir.sh  first!).  build_extensions_dir.sh",
            "title": "Getting Stuff Into The Container"
        },
        {
            "location": "/Service_mediawiki/#enabling-mediawiki-math",
            "text": "Note that we have one last task to complete,\nand that is enabling the math extensions so that \nwe can add formulas to our wiki.  To do this, we have to add the following aptitude\npackages to an  apt-get install  command in the \nDockerfile:  RUN apt-get update && \\\n    apt-get install -y build-essential \\\n            dvipng \\\n            ocaml \\\n            ghostscript \\\n            imagemagick \\\n            texlive-latex-base \\\n            texlive-latex-extra \\\n            texlive-fonts-recommended \\\n            texlive-lang-greek \\\n            texlive-latex-recommended  (Note: ocaml is a language required to make texvc , covered below.)  Next, we need to shim a make command \ninto the container's entrypoint command,\nbefore we run the Apache web server.  To enable equations and math, we need to make\na utility called  texvc  by running  make  in the \nMath extension directory.   We modify the  CMD  directive in the Dockerfile,\nwhich normally runs  apache2-foreground  \nin the stock MediaWiki container.  Change the original  CMD  from this:  CMD apache2-foreground  to this:  CMD cd /var/www/html/extensions/Math/math && make && apache2-foreground",
            "title": "Enabling MediaWiki Math"
        },
        {
            "location": "/Service_mediawiki/#updating-skin-or-localsettingsphp",
            "text": "Note that if you update the MediaWiki skin \nor the LocalSettings.php file, \nyou will need to rebuild the container\nand restart it.  (It's a pain in the ass, but hard to avoid.)  Alternatively, you can use  docker cp  to\ncopy a new  LocalSettings.php  or \nskins directory into the running\nMediaWiki container. These changes\nwill be reflected immediately in the \nwiki interface.  (Be careful with this method!!!)  Best of all possible worlds:\nyour  LocalSettings.php \nand  skins/  directory\nis under version control,\nas in  wiki/charlesreid1-config \non git.charlesreid1.com,\nand can be updated with a \ngit push or git pull.  (This is not currently how\nit is structured, as the \nskin and LocalSettings.php\nfiles are not under version \ncontrol in the container. \nThis would be difficult for \nthe same reason that it is \ndifficult to bind-mount\na file directly into  /var/www/html  - because\nit is also difficult \nto have a particular \nfile under version control\nwhen there are a \nlarge number of other files\nin that directory.)",
            "title": "Updating Skin or LocalSettings.php"
        },
        {
            "location": "/Service_mediawiki/#a-way-out-a-path-forward-a-glimmer-of-hope",
            "text": "How might we fix this nested, nightarish mess?  A couple of things have to happen:    Docker needs to provide better control over user ownership\n    and file permissions for bind-mounted directories.\n    There are some really ugly, hacky shims that are \n    required because the user permissions of everything\n    are buggered from the start.    MediaWiki needs to put user configuration files\n    into a configuration folder. For example, \n     nginx  looks in a folder  /etc/nginx/  for \n    any and all configuration files. This allows\n    bind-mounting a configuration directory \n    to  /etc/nginx/  without complication.\n    Unfortunately, MediaWiki mixes site-specific user files\n    with generic, common-across-all-MediaWikis\n    php files, making it difficult to version-control\n    site-specific user files.",
            "title": "A Way Out? A Path Forward? A Glimmer of Hope?"
        },
        {
            "location": "/Service_mediawiki/#utilities",
            "text": "There are utilities for MediaWiki in  utils-mw :   backup_wikifiles.sh  - back up wiki image files to a tarball  restore_wikifiles.sh  - restore backed up image files from a tarball  update_wikidb.sh  - one-time script to update the wiki database after a version bump",
            "title": "Utilities"
        },
        {
            "location": "/Service_apachephp/",
            "text": "Apache + PHP\n\n\nThis describes the container-specific\ndetails of the Apache part of the \nApache-MediaWiki container.\n\n\nAlso see \nMediaWiki\n.\n\n\nConfiguration Files and Folders\n\n\nWe have two Apache configuration files\nto set up Apache:\n\n\n\n\nports.conf\n sets the port Apache listens on\n\n\nwiki.conf\n sets the \n<VirtualHost>\n block for the wiki\n\n\n\n\nWhere Does Stuff Live?\n\n\nThe \nports.conf\n and \nwiki.conf\n configuration files\nlive in the \nd-mediawiki\n submodule\n(see \ndocker/d-mediawiki\n\non git.charlesreid1.com),\nin the \ncharlesreid1-config\n\nsub-submodule (see \nwiki/charlesreid1-config\n\non git.charlesreid1.com),\nin the \napache/\n directory.\n\n\nSee \nwiki/charlesreid1-config\n\non git.charlesreid1.com.\n\n\nGetting Stuff Into The Container\n\n\nUnlike MediaWiki, Apache has a sane way\nof separating the static program files\nfrom the instance-specific configuration\nfiles.\n\n\nWe bind-mount the directory containing \nApache \n*.conf\n files \ninto the container at \n\n/etc/nginx/conf.d\n\nvia the following line\nin the docker-compose file:\n\n\nservices:\n  ...\n  stormy_nginx:\n    ...\n    volumes:\n      - \"./d-nginx-charlesreid1/conf.d:/etc/nginx/conf.d:ro\"\n\n\n\n\nThat's it!",
            "title": "Pod Service: Apache/PHP"
        },
        {
            "location": "/Service_apachephp/#apache-php",
            "text": "This describes the container-specific\ndetails of the Apache part of the \nApache-MediaWiki container.  Also see  MediaWiki .",
            "title": "Apache + PHP"
        },
        {
            "location": "/Service_apachephp/#configuration-files-and-folders",
            "text": "We have two Apache configuration files\nto set up Apache:   ports.conf  sets the port Apache listens on  wiki.conf  sets the  <VirtualHost>  block for the wiki",
            "title": "Configuration Files and Folders"
        },
        {
            "location": "/Service_apachephp/#where-does-stuff-live",
            "text": "The  ports.conf  and  wiki.conf  configuration files\nlive in the  d-mediawiki  submodule\n(see  docker/d-mediawiki \non git.charlesreid1.com),\nin the  charlesreid1-config \nsub-submodule (see  wiki/charlesreid1-config \non git.charlesreid1.com),\nin the  apache/  directory.  See  wiki/charlesreid1-config \non git.charlesreid1.com.",
            "title": "Where Does Stuff Live?"
        },
        {
            "location": "/Service_apachephp/#getting-stuff-into-the-container",
            "text": "Unlike MediaWiki, Apache has a sane way\nof separating the static program files\nfrom the instance-specific configuration\nfiles.  We bind-mount the directory containing \nApache  *.conf  files \ninto the container at  /etc/nginx/conf.d \nvia the following line\nin the docker-compose file:  services:\n  ...\n  stormy_nginx:\n    ...\n    volumes:\n      - \"./d-nginx-charlesreid1/conf.d:/etc/nginx/conf.d:ro\"  That's it!",
            "title": "Getting Stuff Into The Container"
        },
        {
            "location": "/Service_mysql/",
            "text": "MySQL Configuration Details\n\n\nThis is the most important part of the MediaWiki\nportion of the charlesreid1 pod. MediaWiki stores\nall of the content of the MediaWiki server,\nso the MediaWiki and MySQL containers must \ncommunicate with one another.\n\n\nThe Container\n\n\nThe MySQL container is straightforward, \nnothing fancy.\n\n\nConfiguration Files and Folders\n\n\nWe don't have an extensive MySQL configuration.\nThe container demostrates how to mount a configuration\nfile into the container, but this is optional.\n\n\nGetting Stuff Into The Container (How To Seed MySQL?)\n\n\nThis section refers to scripts contained in \nthe \nutils-mysql\n directory.\n\n\nThe MySQL data must come from a seed\n(what we call a krash seed). This seed\nconsists of a prior backup of the MediaWiki\nMySQL database, from which the database\ncan be restored.\n\n\nThere are both backup and restore scripts\nin the repo under \nutils-mysql\n.\n\n\nRunning the \nmysqldump\n tool will dump \ndatabase backup files in \n.sql\n format.\nThese can be created using the \ndump_database.sh\n\nscript.\n\n\nThese \n.sql\n files can be used to restore a \nMySQL database using the \nrestore_database.sh\n.\n\n\nUtilities\n\n\nThere are utilities for MySQL in \nutils-mysql\n:\n\n\n\n\ndump_databases.sh\n - create an \n..sql\n dump file from a database\n\n\nrestore_database.sh\n - restore a database from an \n.sql\n dump file",
            "title": "Pod Service: MySQL"
        },
        {
            "location": "/Service_mysql/#mysql-configuration-details",
            "text": "This is the most important part of the MediaWiki\nportion of the charlesreid1 pod. MediaWiki stores\nall of the content of the MediaWiki server,\nso the MediaWiki and MySQL containers must \ncommunicate with one another.",
            "title": "MySQL Configuration Details"
        },
        {
            "location": "/Service_mysql/#the-container",
            "text": "The MySQL container is straightforward, \nnothing fancy.",
            "title": "The Container"
        },
        {
            "location": "/Service_mysql/#configuration-files-and-folders",
            "text": "We don't have an extensive MySQL configuration.\nThe container demostrates how to mount a configuration\nfile into the container, but this is optional.",
            "title": "Configuration Files and Folders"
        },
        {
            "location": "/Service_mysql/#getting-stuff-into-the-container-how-to-seed-mysql",
            "text": "This section refers to scripts contained in \nthe  utils-mysql  directory.  The MySQL data must come from a seed\n(what we call a krash seed). This seed\nconsists of a prior backup of the MediaWiki\nMySQL database, from which the database\ncan be restored.  There are both backup and restore scripts\nin the repo under  utils-mysql .  Running the  mysqldump  tool will dump \ndatabase backup files in  .sql  format.\nThese can be created using the  dump_database.sh \nscript.  These  .sql  files can be used to restore a \nMySQL database using the  restore_database.sh .",
            "title": "Getting Stuff Into The Container (How To Seed MySQL?)"
        },
        {
            "location": "/Service_mysql/#utilities",
            "text": "There are utilities for MySQL in  utils-mysql :   dump_databases.sh  - create an  ..sql  dump file from a database  restore_database.sh  - restore a database from an  .sql  dump file",
            "title": "Utilities"
        },
        {
            "location": "/Service_phpmyadmin/",
            "text": "",
            "title": "Pod Service: phpMyAdmin"
        },
        {
            "location": "/Service_nginx/",
            "text": "",
            "title": "Pod Service: nginx"
        },
        {
            "location": "/Service_pythonfiles/",
            "text": "",
            "title": "Pod Service: Python File Server"
        },
        {
            "location": "/Service_gitea/",
            "text": "",
            "title": "Pod Service: Gitea"
        }
    ]
}