{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"pod-charlesreid1 \u00b6 This repo contains a docker compose file for running the charlesreid1.com site. Services \u00b6 The services available through pod-charlesreid1 are: mediawiki apache + php mysql phpmyadmin nginx + ssl python (in progress) gitea (in progress) Links \u00b6 See the documentation site here: https://pages.charlesreid1.com/pod-charlesreid1 Or visit docs/index.md . Source code on git.charlesreid1.com: https://git.charlesreid1.com/docker/pod-charlesreid1 Source code on github.com: https://github.com/charlesreid1-docker/pod-charlesreid1 Quick Start \u00b6 From your project directory, start up the pod: $ docker-compose up If you want to rebuild the images before starting them (i.e., if you changed the Dockerfile and want to rebuild the Docker image), use the --build flag: $ docker-compose up --build If you only want to rebuild the images without starting the Docker pod, use the build verb: $ docker-compose build And finally, if you want to rebuild every container from scratch, rather than using cached data (note that this may take a while), add the --no-cache flag: $ docker-compose build --no-cache IMPORTANT: You should modify the contents of d-mediawiki/charlesreid1-config/ (which is the repository https://github.com/charlesreid1-docker/charlesreid1-wiki-config ) to make the MediaWiki extensions folder and turn the configuration file templates into actual, usable configuration files. Running \u00b6 See Running.md for info about running this docker pod: Running the Docker Pod from Comand Line Running the Docker Pod as a Startup Service Workflow for Charlesreid1 Docker Pod Updates Restoring the Docker Pod from Backups Volumes \u00b6 See Volumes.md for info about data and volumes used by this docker pod: Persistent Data Volumes nginx nginx + lets encrypt ssl certificates nginx static content nginx bind-mounted files mysql mediawiki mediawiki data volume mediawiki bind-mounted files gitea gitea data volume gitea bind-mounted files python file server (pyfiles) pyfiles directory Backups \u00b6 There are a number of directories containing utility scripts - these are mostly dedicated to creating backups of any non-version-controlled data inside the container. See Backups.md for coverage of backup and utility scripts. utils-backups - backup utilities (for cron jobs) utils-mw - mediawiki backup utilities utils-mysql mysql backup utilities Domains and Ports \u00b6 See Domains and Ports.md for info about top-level domain names and ports used by this docker pod. The domains ports document covers: Domains nginx domain handling Ports nginx ports mediawiki/apache ports phpmyadmin ports mysql ports gitea ports python file server ports Additional Port Info \u00b6 The apache-mediawiki combination is running an apache service listening on port 8989. This can be adjusted, but should be adjusted in the Dockerfile, ports.conf , and wiki.conf . The apache service listens on all interfaces (hence *:8989 in the apache conf file), but there is no port mapping specified in docker-compose.yml so it does not listen on any public interfaces. Thus, the wiki is not publicly accessible via port 8989, but the wiki is available via port 8989 to any container linked to, or connected to the same network as, the mediawiki apache container. Meanwhile, the nginx container has a public interface listening on port 80 and another listening on port 443. nginx listens for requests going to the wiki, detected via the url resource prefix being /w/ or /wiki/ , and acts as a reverse proxy, forwarding the requests to Apache. The user transparently sees everything happening via port 80 or (preferrably) 443, but on the backend nginx is passing along the URL request and returning the result. Subdomains are served via reverse proxy on port 7777+. The webhook server is a flask server listening on port 5000. Secrets \u00b6 See Secrets.md for more info about getting secrets like passwords and sensitive files into various containers in the pod. The important bit: we use root.password to store the password, and pass it into containers as an environment variable. Only this top-level pod-charlesreid1 repo should use the file root.password . Details covered on the secrets page: mysql database root password mediawiki mysql database root password gitea secret key and session id nginx ssl certificates Container-Specific Configuration Details \u00b6 Each container has a different way of getting configuration files into the container. In the following documents we cover the specifics of each container. mediawiki apache + php mysql phpmyadmin nginx + ssl python gitea Links \u00b6 docker compose documentation: getting started set environment variables in containers","title":"Index"},{"location":"#pod-charlesreid1","text":"This repo contains a docker compose file for running the charlesreid1.com site.","title":"pod-charlesreid1"},{"location":"#services","text":"The services available through pod-charlesreid1 are: mediawiki apache + php mysql phpmyadmin nginx + ssl python (in progress) gitea (in progress)","title":"Services"},{"location":"#links","text":"See the documentation site here: https://pages.charlesreid1.com/pod-charlesreid1 Or visit docs/index.md . Source code on git.charlesreid1.com: https://git.charlesreid1.com/docker/pod-charlesreid1 Source code on github.com: https://github.com/charlesreid1-docker/pod-charlesreid1","title":"Links"},{"location":"#quick-start","text":"From your project directory, start up the pod: $ docker-compose up If you want to rebuild the images before starting them (i.e., if you changed the Dockerfile and want to rebuild the Docker image), use the --build flag: $ docker-compose up --build If you only want to rebuild the images without starting the Docker pod, use the build verb: $ docker-compose build And finally, if you want to rebuild every container from scratch, rather than using cached data (note that this may take a while), add the --no-cache flag: $ docker-compose build --no-cache IMPORTANT: You should modify the contents of d-mediawiki/charlesreid1-config/ (which is the repository https://github.com/charlesreid1-docker/charlesreid1-wiki-config ) to make the MediaWiki extensions folder and turn the configuration file templates into actual, usable configuration files.","title":"Quick Start"},{"location":"#running","text":"See Running.md for info about running this docker pod: Running the Docker Pod from Comand Line Running the Docker Pod as a Startup Service Workflow for Charlesreid1 Docker Pod Updates Restoring the Docker Pod from Backups","title":"Running"},{"location":"#volumes","text":"See Volumes.md for info about data and volumes used by this docker pod: Persistent Data Volumes nginx nginx + lets encrypt ssl certificates nginx static content nginx bind-mounted files mysql mediawiki mediawiki data volume mediawiki bind-mounted files gitea gitea data volume gitea bind-mounted files python file server (pyfiles) pyfiles directory","title":"Volumes"},{"location":"#backups","text":"There are a number of directories containing utility scripts - these are mostly dedicated to creating backups of any non-version-controlled data inside the container. See Backups.md for coverage of backup and utility scripts. utils-backups - backup utilities (for cron jobs) utils-mw - mediawiki backup utilities utils-mysql mysql backup utilities","title":"Backups"},{"location":"#domains-and-ports","text":"See Domains and Ports.md for info about top-level domain names and ports used by this docker pod. The domains ports document covers: Domains nginx domain handling Ports nginx ports mediawiki/apache ports phpmyadmin ports mysql ports gitea ports python file server ports","title":"Domains and Ports"},{"location":"#additional-port-info","text":"The apache-mediawiki combination is running an apache service listening on port 8989. This can be adjusted, but should be adjusted in the Dockerfile, ports.conf , and wiki.conf . The apache service listens on all interfaces (hence *:8989 in the apache conf file), but there is no port mapping specified in docker-compose.yml so it does not listen on any public interfaces. Thus, the wiki is not publicly accessible via port 8989, but the wiki is available via port 8989 to any container linked to, or connected to the same network as, the mediawiki apache container. Meanwhile, the nginx container has a public interface listening on port 80 and another listening on port 443. nginx listens for requests going to the wiki, detected via the url resource prefix being /w/ or /wiki/ , and acts as a reverse proxy, forwarding the requests to Apache. The user transparently sees everything happening via port 80 or (preferrably) 443, but on the backend nginx is passing along the URL request and returning the result. Subdomains are served via reverse proxy on port 7777+. The webhook server is a flask server listening on port 5000.","title":"Additional Port Info"},{"location":"#secrets","text":"See Secrets.md for more info about getting secrets like passwords and sensitive files into various containers in the pod. The important bit: we use root.password to store the password, and pass it into containers as an environment variable. Only this top-level pod-charlesreid1 repo should use the file root.password . Details covered on the secrets page: mysql database root password mediawiki mysql database root password gitea secret key and session id nginx ssl certificates","title":"Secrets"},{"location":"#container-specific-configuration-details","text":"Each container has a different way of getting configuration files into the container. In the following documents we cover the specifics of each container. mediawiki apache + php mysql phpmyadmin nginx + ssl python gitea","title":"Container-Specific Configuration Details"},{"location":"#links_1","text":"docker compose documentation: getting started set environment variables in containers","title":"Links"},{"location":"Backups/","text":"Backups \u00b6 Krash Seed \u00b6 By competely containerizing charlesreid1.com, all of the static files for running programs come from docker container images, and all configuration files come from git repositories under version control at git.charlesreid1.com/docker . That just leaves the core data for each service, which is what the backup and restore scripts handle. This service data consists of the following: MediaWiki MySQL database dump (.sql) MediaWiki images directory (.tar.gz) Gitea repository dump (.zip) Gitea avatar images (.zip) These four files form a \"krash seed\" for charlesreid1.com. MySQL Backup/Restore Scripts \u00b6 To create a MySQL backup, use the utils-mysql/dump_database.sh script. dump_database.sh script: Dump a database to an .sql file from the stormy_mysql container. ./dump_database.sh <sql-dump-file> Example: ./dump_database.sh /path/to/wikidb_dump.sql MediaWiki Backup/Restore Scripts \u00b6 backup_wikifiles.sh script: Create a tar file containing wiki files from the stormy_mw container ./backup_wikifiles.sh <tar-file> Example: ./backup_wikifiles.sh /path/to/wikifiles.tar.gz Gitea Backup/Restore Scripts \u00b6 Utilities \u00b6 Utilities are kept in the utils-* folders. MySQL Utilities \u00b6 MediaWiki Utilities \u00b6 MySQL Utilities \u00b6","title":"Backups"},{"location":"Backups/#backups","text":"","title":"Backups"},{"location":"Backups/#krash-seed","text":"By competely containerizing charlesreid1.com, all of the static files for running programs come from docker container images, and all configuration files come from git repositories under version control at git.charlesreid1.com/docker . That just leaves the core data for each service, which is what the backup and restore scripts handle. This service data consists of the following: MediaWiki MySQL database dump (.sql) MediaWiki images directory (.tar.gz) Gitea repository dump (.zip) Gitea avatar images (.zip) These four files form a \"krash seed\" for charlesreid1.com.","title":"Krash Seed"},{"location":"Backups/#mysql-backuprestore-scripts","text":"To create a MySQL backup, use the utils-mysql/dump_database.sh script. dump_database.sh script: Dump a database to an .sql file from the stormy_mysql container. ./dump_database.sh <sql-dump-file> Example: ./dump_database.sh /path/to/wikidb_dump.sql","title":"MySQL Backup/Restore Scripts"},{"location":"Backups/#mediawiki-backuprestore-scripts","text":"backup_wikifiles.sh script: Create a tar file containing wiki files from the stormy_mw container ./backup_wikifiles.sh <tar-file> Example: ./backup_wikifiles.sh /path/to/wikifiles.tar.gz","title":"MediaWiki Backup/Restore Scripts"},{"location":"Backups/#gitea-backuprestore-scripts","text":"","title":"Gitea Backup/Restore Scripts"},{"location":"Backups/#utilities","text":"Utilities are kept in the utils-* folders.","title":"Utilities"},{"location":"Backups/#mysql-utilities","text":"","title":"MySQL Utilities"},{"location":"Backups/#mediawiki-utilities","text":"","title":"MediaWiki Utilities"},{"location":"Backups/#mysql-utilities_1","text":"","title":"MySQL Utilities"},{"location":"Ports/","text":"Domains and Ports \u00b6 Domains \u00b6 There are three domains pointing to this server: charlesreid1.com charlesreid1.red charlesreid1.blue These are pointing to the server's IP address using an A NAME DNS record. There are also various subdomains set up (www, git, files), all pointing to the same location. nginx domain handling \u00b6 Nginx handles all of the domains by specifying a different domain_name in each server{} block of the nginx config files. For example: server { listen 80; listen [::]:80; server_name charlesreid1.com; ... } server { listen 80; listen [::]:80; server_name charlesreid1.blue; ... } server { listen 80; listen [::]:80; server_name charlesreid1.red; ... } See the conf.d dir of d-nginx-charlesreid1 . We will cover this in the nginx ports section, but all http urls are redirected to https urls. Ports \u00b6 overview \u00b6 The apache-mediawiki combination is running an apache service listening on port 8989. This can be adjusted, but should be adjusted in the Dockerfile, ports.conf , and wiki.conf . The apache service listens on all interfaces (hence *:8989 in the apache conf file), but there is no port mapping specified in docker-compose.yml so it does not listen on any public interfaces. Thus, the wiki is not publicly accessible via port 8989, but the wiki is available via port 8989 to any container linked to, or connected to the same network as, the mediawiki apache container. Meanwhile, the nginx container has a public interface listening on port 80 and another listening on port 443. nginx listens for requests going to the wiki, detected via the url resource prefix being /w/ or /wiki/ , and acts as a reverse proxy, forwarding the requests to Apache. The user transparently sees everything happening via port 80 or (preferrably) 443, but on the backend nginx is passing along the URL request and returning the result. Subdomains are served via reverse proxy on port 7777+. The webhook server is a flask server listening on port 50000. nginx ports \u00b6 Also see nginx service . Nginx has two main public-facing ports: port 80 (HTTP) and port 443 (HTTPS). All requests to http:// urls go to port 80, and all requests to https:// urls go to port 443. The server will automatically redirect all requests to port 80 to port 443, turning all http requests into https requests. Nginx also exposes port 3000 and forwards it along to git.charlesreid1.com . This is for legacy reasons. To work with MediaWiki, nginx must implement rewrite rules: nginx listens for requests going to wiki URLs (prefixed with /w/ or /wiki ) and proxies those to the correct container. mediawiki/apache ports \u00b6 Also see mediawiki service and apache/php service . The MediaWiki server runs on a PHP and Apache stack. Inside the MediaWiki container, Apache listens on port 8989. This port only connects to the nginx container, so nginx is the only service that can connect to MediaWiki, and only over port 8989. This nginx-apache connection is not encrypted because it happens on the same machine. When the user connects to the wiki, for example at the url https://charlesreid1.com/wiki/Nmap the user's connection is with the nginx server. The session is an https session happening over port 443 and signed by nginx's certificates. If the user goes to http://charlesreid1.com/wiki/Nmap on port 80, this is rewritten to https://charlesreid1.com/wiki/Nmap on port 443. In nginx, this is done with a 301: server { listen 80; listen [::]:80; server_name charlesreid1.com; location / { return 301 https://charlesreid1.com$request_uri; } } Note that nginx plays the role of a central dispatcher in the charlesreid1 pod - all containers connect to nginx and only nginx, while nginx exposes each container to the outside world via requests for various subdomains being redirected to different ports. phpmyadmin ports \u00b6 Also see phpmyadmin service . phpMyAdmin provides a web interface for MySQL databases. This follows a similar pattern to the MediaWiki Apache container: The phpMyAdmin container is connected to the MySQL container via the docker network created by the docker-compose command (no container links needed) The phpMyAdmin container runs an HTTP web interface available inside the container on port 80. This service is exposed on port 80 on the internal docker network only. Since phpMyAdmin only listens on the Docker pod network for incoming requests, all requests to phpMyAdmin must come through nginx via reverse proxy. These are forwarded to port 80 of the phpMyAdmin container on the back end. We keep phpMyAdmin disabled on a regular basis, as it is not heavily used and provides access to sensitive data and operations. To control access to phpMyAdmin, configure the nginx service to whitelist certain IPs to access phpMyAdmin (or shut off all access). mysql ports \u00b6 Also see mysql service . The MySQL container listens on port 3306 by default. The container is only bound to the MediaWiki container, so MediaWiki is the only service that can access MySQL. gitea ports \u00b6 Also see gitea service . Requests for the subdomain git.charlesreid1.com are redirected to port 3000 on the docker internal container network, where gitea is listening. Like the MediaWiki and phpMyAdmin containers, this follows the same reverse proxy pattern: The nginx service handles front-end requests and reverse proxies those rquests to gitea over the internal docker container network. Gitea listens to port 3000 and is bound to the local docker network only. Gitea does not implement HTTP on the back end; nginx handles HTTPS with client on the front end. python file server ports \u00b6 Also see python files service . We have a simple, lightweight Python HTTP server on port 8081 on the Docker network. This container runs the following Python command to start the server: python -m http.server -b <bind-address> 8081 This works because Python provides a built-in HTTP server that, if no index.html file is present, will provide a directory listing. This is as simple as it gets, as far as file servers go. This follows the same reverse proxy pattern: Python HTTP server listens for incoming requests on port 8081 on the Docker network only. Client requests are reverse proxied by d-nginx-charlesreid1 on the front end. The server does not handle HTTPS, this is also handled by the nginx container on the frontend. The bind address and port of the Python HTTP server are set in the command line. The <bind-address> should be set to the name of the docker container image ( stormy_files ). The command python -m http.server -b stormy_files 8081 listens on port 8081 inside the python file server container stormy_files (the container itself). The nginx server reverse-proxies requests for https://files.charlesreid1.com and forwards them to the container. Note: this container can be expanded to a container that serves multiple directories on multiple ports by using twisted. See the d-python-helium repository for an example.","title":"Domains and Ports"},{"location":"Ports/#domains-and-ports","text":"","title":"Domains and Ports"},{"location":"Ports/#domains","text":"There are three domains pointing to this server: charlesreid1.com charlesreid1.red charlesreid1.blue These are pointing to the server's IP address using an A NAME DNS record. There are also various subdomains set up (www, git, files), all pointing to the same location.","title":"Domains"},{"location":"Ports/#nginx-domain-handling","text":"Nginx handles all of the domains by specifying a different domain_name in each server{} block of the nginx config files. For example: server { listen 80; listen [::]:80; server_name charlesreid1.com; ... } server { listen 80; listen [::]:80; server_name charlesreid1.blue; ... } server { listen 80; listen [::]:80; server_name charlesreid1.red; ... } See the conf.d dir of d-nginx-charlesreid1 . We will cover this in the nginx ports section, but all http urls are redirected to https urls.","title":"nginx domain handling"},{"location":"Ports/#ports","text":"","title":"Ports"},{"location":"Ports/#overview","text":"The apache-mediawiki combination is running an apache service listening on port 8989. This can be adjusted, but should be adjusted in the Dockerfile, ports.conf , and wiki.conf . The apache service listens on all interfaces (hence *:8989 in the apache conf file), but there is no port mapping specified in docker-compose.yml so it does not listen on any public interfaces. Thus, the wiki is not publicly accessible via port 8989, but the wiki is available via port 8989 to any container linked to, or connected to the same network as, the mediawiki apache container. Meanwhile, the nginx container has a public interface listening on port 80 and another listening on port 443. nginx listens for requests going to the wiki, detected via the url resource prefix being /w/ or /wiki/ , and acts as a reverse proxy, forwarding the requests to Apache. The user transparently sees everything happening via port 80 or (preferrably) 443, but on the backend nginx is passing along the URL request and returning the result. Subdomains are served via reverse proxy on port 7777+. The webhook server is a flask server listening on port 50000.","title":"overview"},{"location":"Ports/#nginx-ports","text":"Also see nginx service . Nginx has two main public-facing ports: port 80 (HTTP) and port 443 (HTTPS). All requests to http:// urls go to port 80, and all requests to https:// urls go to port 443. The server will automatically redirect all requests to port 80 to port 443, turning all http requests into https requests. Nginx also exposes port 3000 and forwards it along to git.charlesreid1.com . This is for legacy reasons. To work with MediaWiki, nginx must implement rewrite rules: nginx listens for requests going to wiki URLs (prefixed with /w/ or /wiki ) and proxies those to the correct container.","title":"nginx ports"},{"location":"Ports/#mediawikiapache-ports","text":"Also see mediawiki service and apache/php service . The MediaWiki server runs on a PHP and Apache stack. Inside the MediaWiki container, Apache listens on port 8989. This port only connects to the nginx container, so nginx is the only service that can connect to MediaWiki, and only over port 8989. This nginx-apache connection is not encrypted because it happens on the same machine. When the user connects to the wiki, for example at the url https://charlesreid1.com/wiki/Nmap the user's connection is with the nginx server. The session is an https session happening over port 443 and signed by nginx's certificates. If the user goes to http://charlesreid1.com/wiki/Nmap on port 80, this is rewritten to https://charlesreid1.com/wiki/Nmap on port 443. In nginx, this is done with a 301: server { listen 80; listen [::]:80; server_name charlesreid1.com; location / { return 301 https://charlesreid1.com$request_uri; } } Note that nginx plays the role of a central dispatcher in the charlesreid1 pod - all containers connect to nginx and only nginx, while nginx exposes each container to the outside world via requests for various subdomains being redirected to different ports.","title":"mediawiki/apache ports"},{"location":"Ports/#phpmyadmin-ports","text":"Also see phpmyadmin service . phpMyAdmin provides a web interface for MySQL databases. This follows a similar pattern to the MediaWiki Apache container: The phpMyAdmin container is connected to the MySQL container via the docker network created by the docker-compose command (no container links needed) The phpMyAdmin container runs an HTTP web interface available inside the container on port 80. This service is exposed on port 80 on the internal docker network only. Since phpMyAdmin only listens on the Docker pod network for incoming requests, all requests to phpMyAdmin must come through nginx via reverse proxy. These are forwarded to port 80 of the phpMyAdmin container on the back end. We keep phpMyAdmin disabled on a regular basis, as it is not heavily used and provides access to sensitive data and operations. To control access to phpMyAdmin, configure the nginx service to whitelist certain IPs to access phpMyAdmin (or shut off all access).","title":"phpmyadmin ports"},{"location":"Ports/#mysql-ports","text":"Also see mysql service . The MySQL container listens on port 3306 by default. The container is only bound to the MediaWiki container, so MediaWiki is the only service that can access MySQL.","title":"mysql ports"},{"location":"Ports/#gitea-ports","text":"Also see gitea service . Requests for the subdomain git.charlesreid1.com are redirected to port 3000 on the docker internal container network, where gitea is listening. Like the MediaWiki and phpMyAdmin containers, this follows the same reverse proxy pattern: The nginx service handles front-end requests and reverse proxies those rquests to gitea over the internal docker container network. Gitea listens to port 3000 and is bound to the local docker network only. Gitea does not implement HTTP on the back end; nginx handles HTTPS with client on the front end.","title":"gitea ports"},{"location":"Ports/#python-file-server-ports","text":"Also see python files service . We have a simple, lightweight Python HTTP server on port 8081 on the Docker network. This container runs the following Python command to start the server: python -m http.server -b <bind-address> 8081 This works because Python provides a built-in HTTP server that, if no index.html file is present, will provide a directory listing. This is as simple as it gets, as far as file servers go. This follows the same reverse proxy pattern: Python HTTP server listens for incoming requests on port 8081 on the Docker network only. Client requests are reverse proxied by d-nginx-charlesreid1 on the front end. The server does not handle HTTPS, this is also handled by the nginx container on the frontend. The bind address and port of the Python HTTP server are set in the command line. The <bind-address> should be set to the name of the docker container image ( stormy_files ). The command python -m http.server -b stormy_files 8081 listens on port 8081 inside the python file server container stormy_files (the container itself). The nginx server reverse-proxies requests for https://files.charlesreid1.com and forwards them to the container. Note: this container can be expanded to a container that serves multiple directories on multiple ports by using twisted. See the d-python-helium repository for an example.","title":"python file server ports"},{"location":"Running/","text":"Running the Charlesreid1 Docker Pod \u00b6 This docker pod runs the main charlesreid1.com site. To run the pod, use the docker-compose command. The Docker Compose File \u00b6 The docker-compose.yml file contains all the directives needed to run a docker pod of containers that make Charlesreid1.com work. Why use docker-compose instead of docker? docker-compose is the preferred way to run multiple containers. Huh? Where's docker-compose.yml?? Instead of a docker-compose.yml file, you'll see a docker-compose.fixme.yml file. You need to fix this YML file by hard-coding your MYSQL password in the file. (There is also a Jinja template, docker-compose.yml.j2 , usable with charlesreid1-ansible .) See the steps below for using the \"fixme\" file. Running Charlesreid1 Docker Pod from Command Line \u00b6 We start by covering how to run the docker pod from the command line. First, set the MySQL password using a sed one-liner: $ sed \"s/REPLACEME/YoFooThisIsYourNewPassword/\" docker-compose.fixme.yml > docker-compose.yml Now you can run the container pod with docker-compose up # interactive docker-compose up -d # detached or, if you want to rebuild all the containers before running up, docker-compose up --build If you just want to rebuild the containers, docker-compose build and this will rebuild the containers from scratch: docker-compose build --no-cache WARNING: for large, complicated container images, this command can take a very long time. Use with care.) You can restart all containers in a pod using the restart command: docker-compose restart WARNING: this will NOT pick up changes to Dockerfiles or to files that are mounted into the container. This simply restarts the container using the same image (in memory) that was previously running, without getting an up-to-date container image. Running Charlesreid1 Docker Pod as Startup Service \u00b6 If you want to run the pod as a startup service, see the scripts/ folder for a startup service that can be used with systemd. This is also included below: pod-charlesreid1.service: [Unit] Description=charlesreid1 docker pod Requires=docker.service After=docker.service [Service] Restart=always ExecStart=/usr/local/bin/docker-compose -f /home/charles/codes/docker/pod-charlesreid1/docker-compose.yml up ExecStop=/usr/local/bin/docker-compose -f /home/charles/codes/docker/pod-charlesreid1/docker-compose.yml stop [Install] WantedBy=default.target Now install the service to /etc/systemd/system/pod-charlesreid1.servce , and activate it: sudo systemctl enable pod-charlesreid1.service Now you can start/stop the service with: sudo systemctl (start|stop) pod-charlesreid1.service NOTE: if you need to debug the containers, or update any config files copied into the container, be sure and stop the service before doing a docker-compose stop or a docker-compose up --build , otherwise the pod will continually respawn. Workflow for Charlesreid1 Docker Pod Updates \u00b6 This section covers a workflow if you're updating the docker pod. As noted above, a simple docker-compose restart won't pick up changes in Dockerfiles or files mounted into the image, so you often need to stop the containers and restart them after rebuilding the container images. However, if you update your files (particularly if you add a lot of new apt packages), it can take a long time to build the containers. This can result in a lot of downtime if you take the containers down before rebuilding them. To minimize downtime, use the following workflow: Run docker-compose build to rebuild the images, leaving the pod running (they are not affected) Run docker-compose down to bring the pod down Run docker-compose up to bring the pod up It may take a few seconds to bring the pod down, and that will be your total amount of downtime. Restoring Docker Pod from Backups \u00b6 Also see Backups.md . Now that the pod is running, you probably need to seed it with data. You will need two mediawiki restore files and two gitea restore files, everything else comes from git.charlesreid1.com or github.com (this will create a bootstrapping problem if you have no git.charlesreid1.com): MediaWiki database backup MediaWiki files (images) backup Gitea dump zip file Gitea avatars zip file Now you can restore the database as follows: MySQL database restore scripts for MediaWiki are in utils-mysql/ dir MediaWiki image directory restore scripts are in utils-mw/ dir Gitea database and avatars come from backups using scripts in utils-gitea/ dir mysql restore \u00b6 To restore a database from a dump: cd utils-mysql/ ./restore_database.sh /path/to/dump/wikidb.sql The MySQL container must be running for this to work. (You may need to adjust the MySQL container name in the script.) mediawiki restore \u00b6 To restore the MediaWiki images directory: cd utils-mw/ ./restore_wikifiles.sh /path/to/wikifiles.tar.gz gitea restore \u00b6 The gitea container can be restored from a backup as follows: cd utils-gitea/ ./restore_gitea.sh /path/to/gitea-dump.zip /path/to/gitea-avatars.zip","title":"Running the Pod"},{"location":"Running/#running-the-charlesreid1-docker-pod","text":"This docker pod runs the main charlesreid1.com site. To run the pod, use the docker-compose command.","title":"Running the Charlesreid1 Docker Pod"},{"location":"Running/#the-docker-compose-file","text":"The docker-compose.yml file contains all the directives needed to run a docker pod of containers that make Charlesreid1.com work. Why use docker-compose instead of docker? docker-compose is the preferred way to run multiple containers. Huh? Where's docker-compose.yml?? Instead of a docker-compose.yml file, you'll see a docker-compose.fixme.yml file. You need to fix this YML file by hard-coding your MYSQL password in the file. (There is also a Jinja template, docker-compose.yml.j2 , usable with charlesreid1-ansible .) See the steps below for using the \"fixme\" file.","title":"The Docker Compose File"},{"location":"Running/#running-charlesreid1-docker-pod-from-command-line","text":"We start by covering how to run the docker pod from the command line. First, set the MySQL password using a sed one-liner: $ sed \"s/REPLACEME/YoFooThisIsYourNewPassword/\" docker-compose.fixme.yml > docker-compose.yml Now you can run the container pod with docker-compose up # interactive docker-compose up -d # detached or, if you want to rebuild all the containers before running up, docker-compose up --build If you just want to rebuild the containers, docker-compose build and this will rebuild the containers from scratch: docker-compose build --no-cache WARNING: for large, complicated container images, this command can take a very long time. Use with care.) You can restart all containers in a pod using the restart command: docker-compose restart WARNING: this will NOT pick up changes to Dockerfiles or to files that are mounted into the container. This simply restarts the container using the same image (in memory) that was previously running, without getting an up-to-date container image.","title":"Running Charlesreid1 Docker Pod from Command Line"},{"location":"Running/#running-charlesreid1-docker-pod-as-startup-service","text":"If you want to run the pod as a startup service, see the scripts/ folder for a startup service that can be used with systemd. This is also included below: pod-charlesreid1.service: [Unit] Description=charlesreid1 docker pod Requires=docker.service After=docker.service [Service] Restart=always ExecStart=/usr/local/bin/docker-compose -f /home/charles/codes/docker/pod-charlesreid1/docker-compose.yml up ExecStop=/usr/local/bin/docker-compose -f /home/charles/codes/docker/pod-charlesreid1/docker-compose.yml stop [Install] WantedBy=default.target Now install the service to /etc/systemd/system/pod-charlesreid1.servce , and activate it: sudo systemctl enable pod-charlesreid1.service Now you can start/stop the service with: sudo systemctl (start|stop) pod-charlesreid1.service NOTE: if you need to debug the containers, or update any config files copied into the container, be sure and stop the service before doing a docker-compose stop or a docker-compose up --build , otherwise the pod will continually respawn.","title":"Running Charlesreid1 Docker Pod as Startup Service"},{"location":"Running/#workflow-for-charlesreid1-docker-pod-updates","text":"This section covers a workflow if you're updating the docker pod. As noted above, a simple docker-compose restart won't pick up changes in Dockerfiles or files mounted into the image, so you often need to stop the containers and restart them after rebuilding the container images. However, if you update your files (particularly if you add a lot of new apt packages), it can take a long time to build the containers. This can result in a lot of downtime if you take the containers down before rebuilding them. To minimize downtime, use the following workflow: Run docker-compose build to rebuild the images, leaving the pod running (they are not affected) Run docker-compose down to bring the pod down Run docker-compose up to bring the pod up It may take a few seconds to bring the pod down, and that will be your total amount of downtime.","title":"Workflow for Charlesreid1 Docker Pod Updates"},{"location":"Running/#restoring-docker-pod-from-backups","text":"Also see Backups.md . Now that the pod is running, you probably need to seed it with data. You will need two mediawiki restore files and two gitea restore files, everything else comes from git.charlesreid1.com or github.com (this will create a bootstrapping problem if you have no git.charlesreid1.com): MediaWiki database backup MediaWiki files (images) backup Gitea dump zip file Gitea avatars zip file Now you can restore the database as follows: MySQL database restore scripts for MediaWiki are in utils-mysql/ dir MediaWiki image directory restore scripts are in utils-mw/ dir Gitea database and avatars come from backups using scripts in utils-gitea/ dir","title":"Restoring Docker Pod from Backups"},{"location":"Running/#mysql-restore","text":"To restore a database from a dump: cd utils-mysql/ ./restore_database.sh /path/to/dump/wikidb.sql The MySQL container must be running for this to work. (You may need to adjust the MySQL container name in the script.)","title":"mysql restore"},{"location":"Running/#mediawiki-restore","text":"To restore the MediaWiki images directory: cd utils-mw/ ./restore_wikifiles.sh /path/to/wikifiles.tar.gz","title":"mediawiki restore"},{"location":"Running/#gitea-restore","text":"The gitea container can be restored from a backup as follows: cd utils-gitea/ ./restore_gitea.sh /path/to/gitea-dump.zip /path/to/gitea-avatars.zip","title":"gitea restore"},{"location":"Secrets/","text":"Secrets \u00b6 MySQL Password \u00b6 The MySQL password has to get into the MySQL and MediaWiki containers. To do this, we hard-code the MySQL password as an environment variable in docker-compose.yml . The file docker-compose.fixme.yml contains the placeholder REPLACEME where the MySQL password goes. To create a docker-compose.yml from docker-compose.fixme.yml : $ sed \"s/REPLACEME/YoFooThisIsYourNewPassword/\" docker-compose.fixme.yml > docker-compose.yml Great if you hard-code the password, but - wasn't that the whole thing we were trying to avoid? Put the password into a file istead, then grab the password from that file and do a find/replace on the docker compose file: $ cat root.password mysecretpassword $ sed \"s/REPLACEME/`cat root.password`/\" docker-compose.fixme.yml > docker-compose.yml The docker-compose.yml file and root.password files are both ignored by version control. Nginx SSL Certificates \u00b6 The other secrets we need to get into the container are the SSL certificates for the nginx container. To generate the SSL certificates using Let's Encrypt, use the script in the certbot directory. These will be stored on the host machine at /etc/letsencrypt/live/example.com/* . To mount the certificates in the directory, we bind-mount the entire /etc/letsencrypt/ directory into the container with the following line in the docker-compose file: services: ... stormy_nginx: ... volumes: - \"/etc/letsencrypt:/etc/letsencrypt\" ... Meanwhile, in the nginx configuration file that's mounted into the container, we have the following in the SSL server blocks (see docker/d-nginx-charlesreid1 ): server { # https://charlesreid1.com listen 443; listen [::]:443; server_name charlesreid1.com; ssl on; ssl_certificate /etc/letsencrypt/live/charlesreid1.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/charlesreid1.com/privkey.pem; include /etc/letsencrypt/options-ssl-nginx.conf; ... }","title":"Secrets"},{"location":"Secrets/#secrets","text":"","title":"Secrets"},{"location":"Secrets/#mysql-password","text":"The MySQL password has to get into the MySQL and MediaWiki containers. To do this, we hard-code the MySQL password as an environment variable in docker-compose.yml . The file docker-compose.fixme.yml contains the placeholder REPLACEME where the MySQL password goes. To create a docker-compose.yml from docker-compose.fixme.yml : $ sed \"s/REPLACEME/YoFooThisIsYourNewPassword/\" docker-compose.fixme.yml > docker-compose.yml Great if you hard-code the password, but - wasn't that the whole thing we were trying to avoid? Put the password into a file istead, then grab the password from that file and do a find/replace on the docker compose file: $ cat root.password mysecretpassword $ sed \"s/REPLACEME/`cat root.password`/\" docker-compose.fixme.yml > docker-compose.yml The docker-compose.yml file and root.password files are both ignored by version control.","title":"MySQL Password"},{"location":"Secrets/#nginx-ssl-certificates","text":"The other secrets we need to get into the container are the SSL certificates for the nginx container. To generate the SSL certificates using Let's Encrypt, use the script in the certbot directory. These will be stored on the host machine at /etc/letsencrypt/live/example.com/* . To mount the certificates in the directory, we bind-mount the entire /etc/letsencrypt/ directory into the container with the following line in the docker-compose file: services: ... stormy_nginx: ... volumes: - \"/etc/letsencrypt:/etc/letsencrypt\" ... Meanwhile, in the nginx configuration file that's mounted into the container, we have the following in the SSL server blocks (see docker/d-nginx-charlesreid1 ): server { # https://charlesreid1.com listen 443; listen [::]:443; server_name charlesreid1.com; ssl on; ssl_certificate /etc/letsencrypt/live/charlesreid1.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/charlesreid1.com/privkey.pem; include /etc/letsencrypt/options-ssl-nginx.conf; ... }","title":"Nginx SSL Certificates"},{"location":"Service_apachephp/","text":"Apache + PHP \u00b6 This describes the container-specific details of the Apache part of the Apache-MediaWiki container. Also see MediaWiki . Configuration Files and Folders \u00b6 We have two Apache configuration files to set up Apache: ports.conf sets the port Apache listens on wiki.conf sets the <VirtualHost> block for the wiki Where Does Stuff Live? \u00b6 The ports.conf and wiki.conf configuration files live in the d-mediawiki submodule (see docker/d-mediawiki on git.charlesreid1.com), in the charlesreid1-config sub-submodule (see wiki/charlesreid1-config on git.charlesreid1.com), in the apache/ directory. See wiki/charlesreid1-config on git.charlesreid1.com. Getting Stuff Into The Container \u00b6 Unlike MediaWiki, Apache has a sane way of separating the static program files from the instance-specific configuration files. We bind-mount the directory containing Apache *.conf files into the container at /etc/nginx/conf.d via the following line in the pod-charlesreid1 docker-compose file : services: ... stormy_nginx: ... volumes: - \"./d-nginx-charlesreid1/conf.d:/etc/nginx/conf.d:ro\" That's it!","title":"Pod Service: Apache/PHP"},{"location":"Service_apachephp/#apache-php","text":"This describes the container-specific details of the Apache part of the Apache-MediaWiki container. Also see MediaWiki .","title":"Apache + PHP"},{"location":"Service_apachephp/#configuration-files-and-folders","text":"We have two Apache configuration files to set up Apache: ports.conf sets the port Apache listens on wiki.conf sets the <VirtualHost> block for the wiki","title":"Configuration Files and Folders"},{"location":"Service_apachephp/#where-does-stuff-live","text":"The ports.conf and wiki.conf configuration files live in the d-mediawiki submodule (see docker/d-mediawiki on git.charlesreid1.com), in the charlesreid1-config sub-submodule (see wiki/charlesreid1-config on git.charlesreid1.com), in the apache/ directory. See wiki/charlesreid1-config on git.charlesreid1.com.","title":"Where Does Stuff Live?"},{"location":"Service_apachephp/#getting-stuff-into-the-container","text":"Unlike MediaWiki, Apache has a sane way of separating the static program files from the instance-specific configuration files. We bind-mount the directory containing Apache *.conf files into the container at /etc/nginx/conf.d via the following line in the pod-charlesreid1 docker-compose file : services: ... stormy_nginx: ... volumes: - \"./d-nginx-charlesreid1/conf.d:/etc/nginx/conf.d:ro\" That's it!","title":"Getting Stuff Into The Container"},{"location":"Service_gitea/","text":"Gitea \u00b6 Gitea is a self-hosted Github clone. It is written in Go, and provides a web interface and an API to interact with an instance of a git server. Gitea manages its own database, so to get data in and out of Gitea, use its dump and load functionality (more below). This page describes how the Gitea container is configured. Configuring Docker Container \u00b6 To run gitea, we use a stock Gitea container image. We set several options in the docker configuration: USER_UID and USER_GID are set to 1000 (this avoids some problems with files that would otherwise be owned by root) Set restart: always to restart the container when there is a failure stormy_gitea: image: gitea/gitea:latest environment: - USER_UID=1000 - USER_GID=1000 restart: always Gitea Volumes \u00b6 The Gitea container stores all of its data in /data/ inside the container. When the container is launched, the custom/ directory in the docker/d-gitea repository is mounted to /data/gitea/ , which is the directory that contains the files that are used to control the way that Gitea pages look. These contain HTML templates used to render different views in Gitea and templates in custom/ will override the default Gitea page templates. A docker volume named stormy_gitea_data is also created and mounted at /data/ . This is a persistent volume that will survive even if the container is shut down. volumes: - \"stormy_gitea_data:/data\" - \"./d-gitea/custom/conf/app.ini:/data/gitea/conf/app.ini\" - \"./d-gitea/custom/public:/data/gitea/public\" - \"./d-gitea/custom/templates:/data/gitea/templates\" Gitea Ports \u00b6 Gitea provides both SSH and HTTPS interfaces, as it has its own built-in web server and SSH server, as well as git server. The server that is hosting the Gitea container and this Docker pod already has an SSH server listening on port 22, so Gitea listens for SSH connections externally on port 222. ports: - \"222:22\" Note that this bypasses our d-nginx-charlesreid1 nginx container entirely and allows clients to connect to Gitea directly. The Gitea server listens for HTTP/HTTPS connections on port 3000, but that is by default only listening on the internal Docker network, which is exactly how we want it. We want all HTTP and HTTPS traffic to be handled by the front-end d-nginx-charlesreid1 container, and it will reverse-proxy HTTP/HTTPS requests to the Gitea container. Gitea Configuration Files \u00b6 app.ini is the name of the configuration file used by Gitea. An example app.ini configuration file is contained in the docker/d-gitea repository, as well as a script to make a configuration file . volumes: - \"stormy_gitea_data:/data\" - \"./d-gitea/custom/conf/app.ini:/data/gitea/conf/app.ini\" Backups \u00b6 Backing Up Gitea \u00b6 Restoring Gitea \u00b6","title":"Pod Service: Gitea"},{"location":"Service_gitea/#gitea","text":"Gitea is a self-hosted Github clone. It is written in Go, and provides a web interface and an API to interact with an instance of a git server. Gitea manages its own database, so to get data in and out of Gitea, use its dump and load functionality (more below). This page describes how the Gitea container is configured.","title":"Gitea"},{"location":"Service_gitea/#configuring-docker-container","text":"To run gitea, we use a stock Gitea container image. We set several options in the docker configuration: USER_UID and USER_GID are set to 1000 (this avoids some problems with files that would otherwise be owned by root) Set restart: always to restart the container when there is a failure stormy_gitea: image: gitea/gitea:latest environment: - USER_UID=1000 - USER_GID=1000 restart: always","title":"Configuring Docker Container"},{"location":"Service_gitea/#gitea-volumes","text":"The Gitea container stores all of its data in /data/ inside the container. When the container is launched, the custom/ directory in the docker/d-gitea repository is mounted to /data/gitea/ , which is the directory that contains the files that are used to control the way that Gitea pages look. These contain HTML templates used to render different views in Gitea and templates in custom/ will override the default Gitea page templates. A docker volume named stormy_gitea_data is also created and mounted at /data/ . This is a persistent volume that will survive even if the container is shut down. volumes: - \"stormy_gitea_data:/data\" - \"./d-gitea/custom/conf/app.ini:/data/gitea/conf/app.ini\" - \"./d-gitea/custom/public:/data/gitea/public\" - \"./d-gitea/custom/templates:/data/gitea/templates\"","title":"Gitea Volumes"},{"location":"Service_gitea/#gitea-ports","text":"Gitea provides both SSH and HTTPS interfaces, as it has its own built-in web server and SSH server, as well as git server. The server that is hosting the Gitea container and this Docker pod already has an SSH server listening on port 22, so Gitea listens for SSH connections externally on port 222. ports: - \"222:22\" Note that this bypasses our d-nginx-charlesreid1 nginx container entirely and allows clients to connect to Gitea directly. The Gitea server listens for HTTP/HTTPS connections on port 3000, but that is by default only listening on the internal Docker network, which is exactly how we want it. We want all HTTP and HTTPS traffic to be handled by the front-end d-nginx-charlesreid1 container, and it will reverse-proxy HTTP/HTTPS requests to the Gitea container.","title":"Gitea Ports"},{"location":"Service_gitea/#gitea-configuration-files","text":"app.ini is the name of the configuration file used by Gitea. An example app.ini configuration file is contained in the docker/d-gitea repository, as well as a script to make a configuration file . volumes: - \"stormy_gitea_data:/data\" - \"./d-gitea/custom/conf/app.ini:/data/gitea/conf/app.ini\"","title":"Gitea Configuration Files"},{"location":"Service_gitea/#backups","text":"","title":"Backups"},{"location":"Service_gitea/#backing-up-gitea","text":"","title":"Backing Up Gitea"},{"location":"Service_gitea/#restoring-gitea","text":"","title":"Restoring Gitea"},{"location":"Service_mediawiki/","text":"MediaWiki Configuration Details \u00b6 This describes the container-specific details of the MediaWiki part of the Apache-MediaWiki container. Also see Apache + PHP . The Container \u00b6 This is based on a MediaWiki container image that runs MediaWiki, PHP, and Apache all in one container. The Apache server is reverse-proxied by nginx in the final pod configuration. Configuration Files and Folders \u00b6 To set up the MediaWiki container, we have to copy in the following files: One configuration file LocalSettings.php Two directories: extensions/ skins/ Both LocalSettings.php and skins/ are under version control. The extensions/ directory is assembled from git repositories directly, and so is not under version control. Where Does Stuff Live? \u00b6 The LocalSettings.php file and skins/ folder live in the d-mediawiki submodule (see docker/d-mediawiki on git.charlesreid1.com), in the charlesreid1-config sub-submodule (see wiki/charlesreid1-config on git.charlesreid1.com), in the mediawiki/ directory. That's also where the extensions/ directory goes. There is also a script in the wiki/charlesreid1-config repo called build_extensions_dir.sh that clone copies of each MediaWiki extension. Inside the MediaWiki container, the live HTML directory is at /var/www/html/ . That is where LocalSettings.php , skins/ , and extensions/ live in the container. The /var/www/html/ directory is marked as a VOLUME in the Dockerfile and is the mount point for a docker data volume, stormy_mediawiki_data . See wiki/charlesreid1-config on git.charlesreid1.com. Getting Stuff Into The Container \u00b6 The configuration files mentioned above (LocalSettings, skins, and extensions) must be copied into the container at build time. This is done in the MediaWiki Dockerfile - see d-mediawiki . Why don't we bind-mount them into the container? We will have problems mounting files to a directory that is itself a mount point. Since /var/www/html/ is a mount point for the MediaWiki container's data volume, to keep the wiki's files persistent, we can't also bind-mount files at /var/www/html/. Additionally, we have to change the permissions of LocalSettings.pp to 600 and change the ownership of all files in /var/www/html/ to www-data:www-data , the Apache web server user, so that it can serve up the wiki. LocalSettings.php is copied into the container at /var/www/html/LocalSettings.php . skins/ is copied into the container at /var/www/html/skins/ (we use our own customized theme, in the Bootstrap2 directory). extensions/ is copied into the container at /var/www/html/extensions/ (make sure you run build_extensions_dir.sh first!). build_extensions_dir.sh Enabling MediaWiki Math \u00b6 Note that we have one last task to complete, and that is enabling the math extensions so that we can add formulas to our wiki. To do this, we have to add the following aptitude packages to an apt-get install command in the Dockerfile: RUN apt-get update && \\ apt-get install -y build-essential \\ dvipng \\ ocaml \\ ghostscript \\ imagemagick \\ texlive-latex-base \\ texlive-latex-extra \\ texlive-fonts-recommended \\ texlive-lang-greek \\ texlive-latex-recommended (Note: ocaml is a language required to make texvc , covered below.) Next, we need to shim a make command into the container's entrypoint command, before we run the Apache web server. To enable equations and math, we need to make a utility called texvc by running make in the Math extension directory. We modify the CMD directive in the Dockerfile, which normally runs apache2-foreground in the stock MediaWiki container. Change the original CMD from this: CMD apache2-foreground to this: CMD cd /var/www/html/extensions/Math/math && make && apache2-foreground Updating Skin or LocalSettings.php \u00b6 Note that if you update the MediaWiki skin or the LocalSettings.php file, you will need to rebuild the container and restart it. (It's a pain in the ass, but hard to avoid.) Alternatively, you can use docker cp to copy a new LocalSettings.php or skins directory into the running MediaWiki container. These changes will be reflected immediately in the wiki interface. (Be careful with this method!!!) Best of all possible worlds: your LocalSettings.php and skins/ directory is under version control, as in wiki/charlesreid1-config on git.charlesreid1.com, and can be updated with a git push or git pull. (This is not currently how it is structured, as the skin and LocalSettings.php files are not under version control in the container. This would be difficult for the same reason that it is difficult to bind-mount a file directly into /var/www/html - because it is also difficult to have a particular file under version control when there are a large number of other files in that directory.) A Way Out? A Path Forward? A Glimmer of Hope? \u00b6 How might we fix this nested, nightarish mess? A couple of things have to happen: Docker needs to provide better control over user ownership and file permissions for bind-mounted directories. There are some really ugly, hacky shims that are required because the user permissions of everything are buggered from the start. MediaWiki needs to put user configuration files into a configuration folder. For example, nginx looks in a folder /etc/nginx/ for any and all configuration files. This allows bind-mounting a configuration directory to /etc/nginx/ without complication. Unfortunately, MediaWiki mixes site-specific user files with generic, common-across-all-MediaWikis php files, making it difficult to version-control site-specific user files. Utilities \u00b6 There are utilities for MediaWiki in utils-mw : backup_wikifiles.sh - back up wiki image files to a tarball from the story_mw container restore_wikifiles.sh - restore backed up image files from a tarball into the story_mw container update_wikidb.sh - one-time script to update the wiki database after a version bump","title":"Pod Service: MediaWiki"},{"location":"Service_mediawiki/#mediawiki-configuration-details","text":"This describes the container-specific details of the MediaWiki part of the Apache-MediaWiki container. Also see Apache + PHP .","title":"MediaWiki Configuration Details"},{"location":"Service_mediawiki/#the-container","text":"This is based on a MediaWiki container image that runs MediaWiki, PHP, and Apache all in one container. The Apache server is reverse-proxied by nginx in the final pod configuration.","title":"The Container"},{"location":"Service_mediawiki/#configuration-files-and-folders","text":"To set up the MediaWiki container, we have to copy in the following files: One configuration file LocalSettings.php Two directories: extensions/ skins/ Both LocalSettings.php and skins/ are under version control. The extensions/ directory is assembled from git repositories directly, and so is not under version control.","title":"Configuration Files and Folders"},{"location":"Service_mediawiki/#where-does-stuff-live","text":"The LocalSettings.php file and skins/ folder live in the d-mediawiki submodule (see docker/d-mediawiki on git.charlesreid1.com), in the charlesreid1-config sub-submodule (see wiki/charlesreid1-config on git.charlesreid1.com), in the mediawiki/ directory. That's also where the extensions/ directory goes. There is also a script in the wiki/charlesreid1-config repo called build_extensions_dir.sh that clone copies of each MediaWiki extension. Inside the MediaWiki container, the live HTML directory is at /var/www/html/ . That is where LocalSettings.php , skins/ , and extensions/ live in the container. The /var/www/html/ directory is marked as a VOLUME in the Dockerfile and is the mount point for a docker data volume, stormy_mediawiki_data . See wiki/charlesreid1-config on git.charlesreid1.com.","title":"Where Does Stuff Live?"},{"location":"Service_mediawiki/#getting-stuff-into-the-container","text":"The configuration files mentioned above (LocalSettings, skins, and extensions) must be copied into the container at build time. This is done in the MediaWiki Dockerfile - see d-mediawiki . Why don't we bind-mount them into the container? We will have problems mounting files to a directory that is itself a mount point. Since /var/www/html/ is a mount point for the MediaWiki container's data volume, to keep the wiki's files persistent, we can't also bind-mount files at /var/www/html/. Additionally, we have to change the permissions of LocalSettings.pp to 600 and change the ownership of all files in /var/www/html/ to www-data:www-data , the Apache web server user, so that it can serve up the wiki. LocalSettings.php is copied into the container at /var/www/html/LocalSettings.php . skins/ is copied into the container at /var/www/html/skins/ (we use our own customized theme, in the Bootstrap2 directory). extensions/ is copied into the container at /var/www/html/extensions/ (make sure you run build_extensions_dir.sh first!). build_extensions_dir.sh","title":"Getting Stuff Into The Container"},{"location":"Service_mediawiki/#enabling-mediawiki-math","text":"Note that we have one last task to complete, and that is enabling the math extensions so that we can add formulas to our wiki. To do this, we have to add the following aptitude packages to an apt-get install command in the Dockerfile: RUN apt-get update && \\ apt-get install -y build-essential \\ dvipng \\ ocaml \\ ghostscript \\ imagemagick \\ texlive-latex-base \\ texlive-latex-extra \\ texlive-fonts-recommended \\ texlive-lang-greek \\ texlive-latex-recommended (Note: ocaml is a language required to make texvc , covered below.) Next, we need to shim a make command into the container's entrypoint command, before we run the Apache web server. To enable equations and math, we need to make a utility called texvc by running make in the Math extension directory. We modify the CMD directive in the Dockerfile, which normally runs apache2-foreground in the stock MediaWiki container. Change the original CMD from this: CMD apache2-foreground to this: CMD cd /var/www/html/extensions/Math/math && make && apache2-foreground","title":"Enabling MediaWiki Math"},{"location":"Service_mediawiki/#updating-skin-or-localsettingsphp","text":"Note that if you update the MediaWiki skin or the LocalSettings.php file, you will need to rebuild the container and restart it. (It's a pain in the ass, but hard to avoid.) Alternatively, you can use docker cp to copy a new LocalSettings.php or skins directory into the running MediaWiki container. These changes will be reflected immediately in the wiki interface. (Be careful with this method!!!) Best of all possible worlds: your LocalSettings.php and skins/ directory is under version control, as in wiki/charlesreid1-config on git.charlesreid1.com, and can be updated with a git push or git pull. (This is not currently how it is structured, as the skin and LocalSettings.php files are not under version control in the container. This would be difficult for the same reason that it is difficult to bind-mount a file directly into /var/www/html - because it is also difficult to have a particular file under version control when there are a large number of other files in that directory.)","title":"Updating Skin or LocalSettings.php"},{"location":"Service_mediawiki/#a-way-out-a-path-forward-a-glimmer-of-hope","text":"How might we fix this nested, nightarish mess? A couple of things have to happen: Docker needs to provide better control over user ownership and file permissions for bind-mounted directories. There are some really ugly, hacky shims that are required because the user permissions of everything are buggered from the start. MediaWiki needs to put user configuration files into a configuration folder. For example, nginx looks in a folder /etc/nginx/ for any and all configuration files. This allows bind-mounting a configuration directory to /etc/nginx/ without complication. Unfortunately, MediaWiki mixes site-specific user files with generic, common-across-all-MediaWikis php files, making it difficult to version-control site-specific user files.","title":"A Way Out? A Path Forward? A Glimmer of Hope?"},{"location":"Service_mediawiki/#utilities","text":"There are utilities for MediaWiki in utils-mw : backup_wikifiles.sh - back up wiki image files to a tarball from the story_mw container restore_wikifiles.sh - restore backed up image files from a tarball into the story_mw container update_wikidb.sh - one-time script to update the wiki database after a version bump","title":"Utilities"},{"location":"Service_mysql/","text":"MySQL Configuration Details \u00b6 This is the most important part of the MediaWiki portion of the charlesreid1 pod. MediaWiki stores all of the content of the MediaWiki server, so the MediaWiki and MySQL containers must communicate with one another. The Container \u00b6 The MySQL container is straightforward, nothing fancy. Configuration Files and Folders \u00b6 We don't have an extensive MySQL configuration. The container demostrates how to mount a configuration file into the container, but this is optional. See this line of the run script in the docker/d-mysql repository. Getting Stuff Into The Container (How To Seed MySQL?) \u00b6 This section refers to scripts contained in the utils-mysql/ directory. The MySQL data must come from a seed (what we call a krash seed). This seed consists of a prior backup of the MediaWiki MySQL database, from which the database can be restored. There are both backup and restore scripts in the repo under utils-mysql/ . The dump_database.sh script will run the mysqldump tool to back up all the databases in the container into a file in .sql format. These .sql files can be used to restore a MySQL database using the restore_database.sh script. Utilities \u00b6 There are utilities for MySQL in utils-mysql : dump_databases.sh - create an .sql dump file from a database restore_database.sh - restore a database from an .sql dump file","title":"Pod Service: MySQL"},{"location":"Service_mysql/#mysql-configuration-details","text":"This is the most important part of the MediaWiki portion of the charlesreid1 pod. MediaWiki stores all of the content of the MediaWiki server, so the MediaWiki and MySQL containers must communicate with one another.","title":"MySQL Configuration Details"},{"location":"Service_mysql/#the-container","text":"The MySQL container is straightforward, nothing fancy.","title":"The Container"},{"location":"Service_mysql/#configuration-files-and-folders","text":"We don't have an extensive MySQL configuration. The container demostrates how to mount a configuration file into the container, but this is optional. See this line of the run script in the docker/d-mysql repository.","title":"Configuration Files and Folders"},{"location":"Service_mysql/#getting-stuff-into-the-container-how-to-seed-mysql","text":"This section refers to scripts contained in the utils-mysql/ directory. The MySQL data must come from a seed (what we call a krash seed). This seed consists of a prior backup of the MediaWiki MySQL database, from which the database can be restored. There are both backup and restore scripts in the repo under utils-mysql/ . The dump_database.sh script will run the mysqldump tool to back up all the databases in the container into a file in .sql format. These .sql files can be used to restore a MySQL database using the restore_database.sh script.","title":"Getting Stuff Into The Container (How To Seed MySQL?)"},{"location":"Service_mysql/#utilities","text":"There are utilities for MySQL in utils-mysql : dump_databases.sh - create an .sql dump file from a database restore_database.sh - restore a database from an .sql dump file","title":"Utilities"},{"location":"Service_nginx/","text":"Nginx \u00b6 This describes the configuration of the main nginx container for the charlesreid1.com pod. Configuration Files \u00b6 The nginx container is critical to routing operations on charlesreid1.com, so we cover how the configuration files are split up and organized on this page, and include a summary of each file below. Where are the nginx config files? \u00b6 Nginx configuration files are located in the d-nginx-charlesreid1 submodule of this repository, which points to the docker/d-nginx-charlesreid1 repository. Within that repository is the conf.d/ folder, which contains several .conf files. What Files Are There? \u00b6 We have three sets of files present: HTTP config files that redirect HTTP traffic on port 80 to be HTTPS traffic on port 443, one for each top-level domain (charlesreid1.com, charlesreid1.blue, and charlesreid1.red): http.com.charlesreid1.conf http.red.charlesreid1.conf http.blue.charlesreid1.conf HTTPS rules for charlesreid1.com endpoints (the wiki, phpMyAdmin, and ignoring .git directories): https.com.charlesreid1.conf https.red.charlesreid1.conf https.blue.charlesreid1.conf HTTPS rules for subdomains (pages.charlesreid1.com, hooks.charlesreid1.com, bots.charlesreid1.com): https.com.charlesreid1.subdomains.conf https.red.charlesreid1.subdomains.conf https.blue.charlesreid1.subdomains.conf HTTP Config Files \u00b6 The HTTP config files are listed below: http.com.charlesreid1.conf http.red.charlesreid1.conf http.blue.charlesreid1.conf The HTTP config files do the following: Requests for port 80 (for a domain or subdomain) are always redirected to port 443 for the same domain/subdomain HTTPS Config Files \u00b6 The HTTPS config files are listed below: https.com.charlesreid1.conf https.red.charlesreid1.conf https.blue.charlesreid1.conf The HTTPS config files (without \"subdomain\" in their name) do the following: Requests for / are redirected to the htdocs folders mentioned above Requests for /w/ or /wiki/ are reverse-proxied to the local Apache+PHP container on port 8989 (Optional) requests for /phpMyAdmin/ are reverse-proxied to the local phpMyAdmin container on port 80 Requests for git.charlesreid1.com are reverse-proxied to the local Gitea container on port 3000 Requests for files.charlesreid1.com are reverse-proxied to the local Python files on port 8081 HTTPS Subdomain Config Files \u00b6 The HTTPS subdomain config files are listed below: https.com.charlesreid1.subdomains.conf https.red.charlesreid1.subdomains.conf https.blue.charlesreid1.subdomains.conf The subdomains config files redirect requests for a set of subdomains on charlesreid1.com, namely: pages.charlesreid1.com hooks.charlesreid1.com bots.charlesreid1.com This charlesreid1.com docker pod will redirect requests for these subdomains to another server running another docker pod, called the webhook docker pod, available at docker/pod-webhooks ). The webhook docker pod runs an nginx server, both to serve up static sites that live under the https://pages.charlesreid1.com domain, and to handle webhook traffic - the container also runs a Python webhook server that receives webhooks from git.charlesreid1.com, which enables push-to-deploy functionality similar to Github Pages. Also see https://pages.charlesreid1.com/pod-webhooks/ . Why All The Config Files? \u00b6 If everything is stuffed into a smaller number of nginx config files, they become long and unwieldy, and more prone to mistakes. HTTP config files only contain redirects HTTPS (no subdomain) config files handle Getting Configuration Files Into Container \u00b6 The configuration files are mounted into the container by bind-mounting the conf.d folder of the d-nginx-charlesreid1 submodule at /et/nginx/conf.d in the container. This is done in the charlesreid1 pod docker-compose file . Static Content \u00b6 The nginx container hosts static content, in addition to serving as a reverse-proxy for several other services. This section covers how static content is treated by the charlesreid1.com nginx container Outside the Container: /www/ \u00b6 Static content hosted by the container is stored on the host machine in /www/ . Each site (e.g., charlesreid1.com) has its own folder, containing the source for the static site and an htdocs folder containing the static content actually being hosted. Additionally, because the static content for the site is actually contained on the gh-pages branch of charlesreid1/charlesreid1.com , the htodcs folder is actually a git repository. When it is cloned, it is cloned such that the git repo's contents go into /www/charlesreid1.com/htdocs/ and the contents of the .git folder go into /www/charlesreid1.com/git . This allows the site static content to be updated to reflect the contents of the gh-pages branch by pulling the latest upstream changes into htdocs. The directory structure used is as follows: /www /charlesreid1.com /charlesreid1-src ...source for pelican site... /htdocs ...static content... /git ...dot git folder... /charlesreid1.blue /charlesreid1-blue-src ...source for pelican site... /htodcs ...static content... /git ...dot git folder... /charlesreid1.red /charlesreid1-red-src ...source for pelican site... /htodcs ...static content... /git ...dot git folder... This directory structure can be achieved using the following bash command: REPOURL=\"https://git.charlesreid1.com/charlesreid1/charlesreid1.com.git\" git -C /www/example.com \\ clone \\ --separate-git-dir=git \\ -b gh-pages \\ $REPOURL htdocs The dotfiles/debian repository contains scripts for krash, which runs the charlesreid1.com pod, to set up the directory structure as above, as well as scripts to pull the latest changes from upstream for each of the live web directories above. Inside the Container: /usr/share/nginx/html \u00b6 Once the contents of the /www/ directory have been set up, the content can be made avialable inside the container by bind-mounting the htdocs directories into the /www/ directory inside the container. This is done with the following volume directives in the docker-compose.yml file : volumes: - \"/www/charlesreid1.blue/htdocs:/www/charlesreid1.blue/htdocs:ro\" - \"/www/charlesreid1.red/htdocs:/www/charlesreid1.red/htdocs:ro\" - \"/www/charlesreid1.com/htdocs:/www/charlesreid1.com/htdocs:ro\" ... Utility Scripts: Updating Site Contents \u00b6 In the krash_scripts/ folder of the debian/dotfiles](https://git.charlesreid1.com/dotfiles/debian) repository, there are several utility scripts to help with setting up and updating this directory structure. To set up the directory structure, use the git_clone_www.sh script . 1 2 3 4 5 6 7 8 9 #!/bin/bash REPOURL = \"https://git.charlesreid1.com/charlesreid1/charlesreid1.com.git\" git -C /www/example.com \\ clone \\ --separate-git-dir = git \\ -b gh-pages \\ $REPOURL htdocs To update the contents of the htdocs/ folder using the latest changes on the gh-pages branch, use the git_pull_www.sh script . 1 2 3 4 5 #!/bin/bash git -C /www/example.com \\ --git-dir = git --work-tree = htdocs \\ pull origin gh-pages SSL Certificates \u00b6 We utilize Let's Encrypt to issue SSL certificates for our domain. This is a pain because of the need to automatically renew certificates every 90 days, and because of missing information in their documentation. Where To Put Certificates \u00b6 We leave the certificates where Let's Encrypt puts them, namely, in /etc/letsencrypt/live . The certificates are bind-mounted into the container at the same location, /etc/letsencrypt/live . The docker-compose.yml file then contains the following: volumes: - \"/etc/letsencrypt:/etc/letsencrypt\" ... Which Server Needs Certificates \u00b6 Because the d-nginx-charlesreid1 docker container is serving as the front-end nginx server handling all incoming charlesreid1.com web requests, it is also the one negotiating HTTPS sessions with clients, so it is the container that needs the Let's Encrypt certificates. This means that, for example, the SSL certificate for pages.charlesreid1.com is on krash, even though the content served up by the site is on blackbeard. Getting and Renewing Certificates \u00b6 Once you have worked everything out and gotten auto-renew cron scripts running smoothly, everything is unicorns and rainbows. But when you hit the Let's Encrypt rate limit because they did not explain it properly in the documentation, you may want everyone to die. Let's Encrypt provides a command line utility called certbot that can be used to automate the process of creating and renewing certificates. See the charlesreid1/certbot repository for scripts. The basic setup is as follows: Use the krash_make_cert.sh script (which wraps the make_cert.sh script) to create SSL certificates for each domain and subdomain Use the krash_renew.sh script (which wraps the renew_cert.sh script) to renew SSL certificates for each domain and subdomain Certificates must be renewed every 90 days. I run the certificate renewal script in the root acount's crontab every 15 days so the certs never expire. Domain Control \u00b6 There are three top-level domains controlled by pod-charlesreid1: https://charlesreid1.com https://charlesreid1.blue https://charlesreid1.red There are several subdomains available on charlesreid1.com. Hosted on krash: https://git.charlesreid1.com - gitea service https://files.charlesreid1.com - static file hosting Hosted on blackbeard: https://pages.charlesreid1.com - push-to-deploy static pages https://hooks.charlesreid1.com - webhook server https://bots.charlesreid1.com - info about bots","title":"Pod Service: nginx"},{"location":"Service_nginx/#nginx","text":"This describes the configuration of the main nginx container for the charlesreid1.com pod.","title":"Nginx"},{"location":"Service_nginx/#configuration-files","text":"The nginx container is critical to routing operations on charlesreid1.com, so we cover how the configuration files are split up and organized on this page, and include a summary of each file below.","title":"Configuration Files"},{"location":"Service_nginx/#where-are-the-nginx-config-files","text":"Nginx configuration files are located in the d-nginx-charlesreid1 submodule of this repository, which points to the docker/d-nginx-charlesreid1 repository. Within that repository is the conf.d/ folder, which contains several .conf files.","title":"Where are the nginx config files?"},{"location":"Service_nginx/#what-files-are-there","text":"We have three sets of files present: HTTP config files that redirect HTTP traffic on port 80 to be HTTPS traffic on port 443, one for each top-level domain (charlesreid1.com, charlesreid1.blue, and charlesreid1.red): http.com.charlesreid1.conf http.red.charlesreid1.conf http.blue.charlesreid1.conf HTTPS rules for charlesreid1.com endpoints (the wiki, phpMyAdmin, and ignoring .git directories): https.com.charlesreid1.conf https.red.charlesreid1.conf https.blue.charlesreid1.conf HTTPS rules for subdomains (pages.charlesreid1.com, hooks.charlesreid1.com, bots.charlesreid1.com): https.com.charlesreid1.subdomains.conf https.red.charlesreid1.subdomains.conf https.blue.charlesreid1.subdomains.conf","title":"What Files Are There?"},{"location":"Service_nginx/#http-config-files","text":"The HTTP config files are listed below: http.com.charlesreid1.conf http.red.charlesreid1.conf http.blue.charlesreid1.conf The HTTP config files do the following: Requests for port 80 (for a domain or subdomain) are always redirected to port 443 for the same domain/subdomain","title":"HTTP Config Files"},{"location":"Service_nginx/#https-config-files","text":"The HTTPS config files are listed below: https.com.charlesreid1.conf https.red.charlesreid1.conf https.blue.charlesreid1.conf The HTTPS config files (without \"subdomain\" in their name) do the following: Requests for / are redirected to the htdocs folders mentioned above Requests for /w/ or /wiki/ are reverse-proxied to the local Apache+PHP container on port 8989 (Optional) requests for /phpMyAdmin/ are reverse-proxied to the local phpMyAdmin container on port 80 Requests for git.charlesreid1.com are reverse-proxied to the local Gitea container on port 3000 Requests for files.charlesreid1.com are reverse-proxied to the local Python files on port 8081","title":"HTTPS Config Files"},{"location":"Service_nginx/#https-subdomain-config-files","text":"The HTTPS subdomain config files are listed below: https.com.charlesreid1.subdomains.conf https.red.charlesreid1.subdomains.conf https.blue.charlesreid1.subdomains.conf The subdomains config files redirect requests for a set of subdomains on charlesreid1.com, namely: pages.charlesreid1.com hooks.charlesreid1.com bots.charlesreid1.com This charlesreid1.com docker pod will redirect requests for these subdomains to another server running another docker pod, called the webhook docker pod, available at docker/pod-webhooks ). The webhook docker pod runs an nginx server, both to serve up static sites that live under the https://pages.charlesreid1.com domain, and to handle webhook traffic - the container also runs a Python webhook server that receives webhooks from git.charlesreid1.com, which enables push-to-deploy functionality similar to Github Pages. Also see https://pages.charlesreid1.com/pod-webhooks/ .","title":"HTTPS Subdomain Config Files"},{"location":"Service_nginx/#why-all-the-config-files","text":"If everything is stuffed into a smaller number of nginx config files, they become long and unwieldy, and more prone to mistakes. HTTP config files only contain redirects HTTPS (no subdomain) config files handle","title":"Why All The Config Files?"},{"location":"Service_nginx/#getting-configuration-files-into-container","text":"The configuration files are mounted into the container by bind-mounting the conf.d folder of the d-nginx-charlesreid1 submodule at /et/nginx/conf.d in the container. This is done in the charlesreid1 pod docker-compose file .","title":"Getting Configuration Files Into Container"},{"location":"Service_nginx/#static-content","text":"The nginx container hosts static content, in addition to serving as a reverse-proxy for several other services. This section covers how static content is treated by the charlesreid1.com nginx container","title":"Static Content"},{"location":"Service_nginx/#outside-the-container-www","text":"Static content hosted by the container is stored on the host machine in /www/ . Each site (e.g., charlesreid1.com) has its own folder, containing the source for the static site and an htdocs folder containing the static content actually being hosted. Additionally, because the static content for the site is actually contained on the gh-pages branch of charlesreid1/charlesreid1.com , the htodcs folder is actually a git repository. When it is cloned, it is cloned such that the git repo's contents go into /www/charlesreid1.com/htdocs/ and the contents of the .git folder go into /www/charlesreid1.com/git . This allows the site static content to be updated to reflect the contents of the gh-pages branch by pulling the latest upstream changes into htdocs. The directory structure used is as follows: /www /charlesreid1.com /charlesreid1-src ...source for pelican site... /htdocs ...static content... /git ...dot git folder... /charlesreid1.blue /charlesreid1-blue-src ...source for pelican site... /htodcs ...static content... /git ...dot git folder... /charlesreid1.red /charlesreid1-red-src ...source for pelican site... /htodcs ...static content... /git ...dot git folder... This directory structure can be achieved using the following bash command: REPOURL=\"https://git.charlesreid1.com/charlesreid1/charlesreid1.com.git\" git -C /www/example.com \\ clone \\ --separate-git-dir=git \\ -b gh-pages \\ $REPOURL htdocs The dotfiles/debian repository contains scripts for krash, which runs the charlesreid1.com pod, to set up the directory structure as above, as well as scripts to pull the latest changes from upstream for each of the live web directories above.","title":"Outside the Container: /www/"},{"location":"Service_nginx/#inside-the-container-usrsharenginxhtml","text":"Once the contents of the /www/ directory have been set up, the content can be made avialable inside the container by bind-mounting the htdocs directories into the /www/ directory inside the container. This is done with the following volume directives in the docker-compose.yml file : volumes: - \"/www/charlesreid1.blue/htdocs:/www/charlesreid1.blue/htdocs:ro\" - \"/www/charlesreid1.red/htdocs:/www/charlesreid1.red/htdocs:ro\" - \"/www/charlesreid1.com/htdocs:/www/charlesreid1.com/htdocs:ro\" ...","title":"Inside the Container: /usr/share/nginx/html"},{"location":"Service_nginx/#utility-scripts-updating-site-contents","text":"In the krash_scripts/ folder of the debian/dotfiles](https://git.charlesreid1.com/dotfiles/debian) repository, there are several utility scripts to help with setting up and updating this directory structure. To set up the directory structure, use the git_clone_www.sh script . 1 2 3 4 5 6 7 8 9 #!/bin/bash REPOURL = \"https://git.charlesreid1.com/charlesreid1/charlesreid1.com.git\" git -C /www/example.com \\ clone \\ --separate-git-dir = git \\ -b gh-pages \\ $REPOURL htdocs To update the contents of the htdocs/ folder using the latest changes on the gh-pages branch, use the git_pull_www.sh script . 1 2 3 4 5 #!/bin/bash git -C /www/example.com \\ --git-dir = git --work-tree = htdocs \\ pull origin gh-pages","title":"Utility Scripts: Updating Site Contents"},{"location":"Service_nginx/#ssl-certificates","text":"We utilize Let's Encrypt to issue SSL certificates for our domain. This is a pain because of the need to automatically renew certificates every 90 days, and because of missing information in their documentation.","title":"SSL Certificates"},{"location":"Service_nginx/#where-to-put-certificates","text":"We leave the certificates where Let's Encrypt puts them, namely, in /etc/letsencrypt/live . The certificates are bind-mounted into the container at the same location, /etc/letsencrypt/live . The docker-compose.yml file then contains the following: volumes: - \"/etc/letsencrypt:/etc/letsencrypt\" ...","title":"Where To Put Certificates"},{"location":"Service_nginx/#which-server-needs-certificates","text":"Because the d-nginx-charlesreid1 docker container is serving as the front-end nginx server handling all incoming charlesreid1.com web requests, it is also the one negotiating HTTPS sessions with clients, so it is the container that needs the Let's Encrypt certificates. This means that, for example, the SSL certificate for pages.charlesreid1.com is on krash, even though the content served up by the site is on blackbeard.","title":"Which Server Needs Certificates"},{"location":"Service_nginx/#getting-and-renewing-certificates","text":"Once you have worked everything out and gotten auto-renew cron scripts running smoothly, everything is unicorns and rainbows. But when you hit the Let's Encrypt rate limit because they did not explain it properly in the documentation, you may want everyone to die. Let's Encrypt provides a command line utility called certbot that can be used to automate the process of creating and renewing certificates. See the charlesreid1/certbot repository for scripts. The basic setup is as follows: Use the krash_make_cert.sh script (which wraps the make_cert.sh script) to create SSL certificates for each domain and subdomain Use the krash_renew.sh script (which wraps the renew_cert.sh script) to renew SSL certificates for each domain and subdomain Certificates must be renewed every 90 days. I run the certificate renewal script in the root acount's crontab every 15 days so the certs never expire.","title":"Getting and Renewing Certificates"},{"location":"Service_nginx/#domain-control","text":"There are three top-level domains controlled by pod-charlesreid1: https://charlesreid1.com https://charlesreid1.blue https://charlesreid1.red There are several subdomains available on charlesreid1.com. Hosted on krash: https://git.charlesreid1.com - gitea service https://files.charlesreid1.com - static file hosting Hosted on blackbeard: https://pages.charlesreid1.com - push-to-deploy static pages https://hooks.charlesreid1.com - webhook server https://bots.charlesreid1.com - info about bots","title":"Domain Control"},{"location":"Service_phpmyadmin/","text":"phpMyAdmin \u00b6 This page describes the container-specific details of the phpMyAdmin container. phpMyAdmin provides a web interface for interacting with MySQL databases and can be connected to the MySQL container to ensure the backup/restore process proceeds smoothly. This is run as a stock phpMyAdmin container - run script is here in the docker/d-phpmyadmin repository on git.charlesreid1.com. The phpMyAdmin service is a web interface that is available on port 80. The container should only be bound to the Docker container network (default behavior). Then any container on the network can reach the container's phpMyAdmin service on port 80. This allows the phpMyAdmin service to be made available at a URL like /phpMyAdmin and have all requests reverse-proxied by the nginx container and passed to port 80 on the back end. The phpMyAdmin service can also be disabled/enabled by commenting it out of the nginx configuration files containing HTTPS rules for the charlesreid1.com domains. See the configuration section of the Nginx container page for more information about the nginx configuration files.","title":"Pod Service: phpMyAdmin"},{"location":"Service_phpmyadmin/#phpmyadmin","text":"This page describes the container-specific details of the phpMyAdmin container. phpMyAdmin provides a web interface for interacting with MySQL databases and can be connected to the MySQL container to ensure the backup/restore process proceeds smoothly. This is run as a stock phpMyAdmin container - run script is here in the docker/d-phpmyadmin repository on git.charlesreid1.com. The phpMyAdmin service is a web interface that is available on port 80. The container should only be bound to the Docker container network (default behavior). Then any container on the network can reach the container's phpMyAdmin service on port 80. This allows the phpMyAdmin service to be made available at a URL like /phpMyAdmin and have all requests reverse-proxied by the nginx container and passed to port 80 on the back end. The phpMyAdmin service can also be disabled/enabled by commenting it out of the nginx configuration files containing HTTPS rules for the charlesreid1.com domains. See the configuration section of the Nginx container page for more information about the nginx configuration files.","title":"phpMyAdmin"},{"location":"Service_pythonfiles/","text":"Python File Server \u00b6 This page describes how pod-charlesreid1 provides a lightweight HTTP file server that is reverse-proxied by nginx to provide a dead-simple file hosting service at files.charlesreid1.com . We use an alpine container with Python 3 for a minimal image size. Python comes with a simple HTTP server built-in that will do the job for us, available through the http.server module (or SimpleHTTPServer in Python 2): python3 -m http.server 8081 We expose this to port 8081 locally, making the service available on the Docker network and therefore available to be reverse-proxied by the nginx container. Files to be served up are located in /www/files/ on the host, which is bind-mounted to /files in the container.","title":"Pod Service: Python File Server"},{"location":"Service_pythonfiles/#python-file-server","text":"This page describes how pod-charlesreid1 provides a lightweight HTTP file server that is reverse-proxied by nginx to provide a dead-simple file hosting service at files.charlesreid1.com . We use an alpine container with Python 3 for a minimal image size. Python comes with a simple HTTP server built-in that will do the job for us, available through the http.server module (or SimpleHTTPServer in Python 2): python3 -m http.server 8081 We expose this to port 8081 locally, making the service available on the Docker network and therefore available to be reverse-proxied by the nginx container. Files to be served up are located in /www/files/ on the host, which is bind-mounted to /files in the container.","title":"Python File Server"},{"location":"Volumes/","text":"Volumes \u00b6 Persistent Data Volumes \u00b6 docker-compose volumes are mostly persistent, but they can be deleted relatively easily. When you're using docker-compose, volumes are persistent through both docker-compose stop and docker-compose down commands. The docker-compose down command will destroy everything including networks and mounted files, while docker-compose stop will just stop the containers. DANGER - DANGER - DANGER If you want to remove the volumes, use docker-compose down -v . docker-compose down -v # DANGER!!! To force removal of the volumes: docker-compose down -v -f # DANGER!!! To see the current list of docker volumes: docker volume ls You can also interact with the volumes individually this way. Run docker volume for help. nginx \u00b6 The nginx service does not have any data volumes, but has several static files that are bind-mounted. Most importantly, nginx handles the SSL certificates for all subdomains. nginx + lets encrypt ssl certificates \u00b6 Rather than fuss with getting the letsencrypt docker image working, we made SSL certs by hand. See git.charlesreid1.com/charlesreid1/certbot Certbot will put the SSL certificates into /etc/letsencrypt/live/example.com . We bind-mount the entire /etc/letsencrypt directory into the same location in the nginx container (see this volumes line in docker-compose.yml ): - \"/etc/letsencrypt:/etc/letsencrypt\" To renew certificates (every few months), just run the certbot script in the certbot repo. nginx static content \u00b6 The main site hosted by nginx (charlesreid1.com) is served up from a directory of static content under version control. This static content is bind-mounted and lives on the host (no data volume is used for nginx). On the host, static site contents are stored at /www/ with a directory structure and corresponding permissions as follows: /www/ # <-- owned by regular user charlesreid1.blue/ # <-- owned by regular user charlesreid1.blue-src/ # <-- owned by regular user <pelican files> htdocs/ # <-- owned by www-data <web site static contents> charlesreid1.red/ # <-- owned by regular user charlesreid1.red-src/ # <-- owned by regular user <pelican files> htdocs/ # <-- owned by www-data <web site static contents> charlesreid1.com/ charlesreid1.com-src/ <pelican files> htdocs/ <web site static contents> ... Each domain has its own directory, in which there is a source directory (git repository containing pelican files) and an htdocs directory (git repository containing live hosted static content). These are mounted in the container at the same location. See the volumes section of the nginx container: - \"/www/charlesreid1.blue/htdocs:/www/charlesreid1.blue/htdocs:ro\" - \"/www/charlesreid1.red/htdocs:/www/charlesreid1.red/htdocs:ro\" - \"/www/charlesreid1.com/htdocs:/www/charlesreid1.com/htdocs:ro\" The source and htdocs directories are separate branches of the same repo. Each website has (TODO: will have) its own repository. The master branch contains the source code for that repository, mainly pelican files plus html/css/js. The pages branch contains the static content to be hosted by the nginx web server. Ownership makes dealing with this stuff a pain in the ass. The htdocs dir must be owned/updated by www-data , so you need to update the git repo contents as that user: sudo -H -u www-data git pull origin pages nginx bind-mounted files \u00b6 We bind-mount a directory conf.d containing nginx configuration files into the container at /etc/nginx/conf.d , which is where nginx automatically looks for and loads configuration files. The custom nginx configuration files are split up by protocol and subdomain, and can be found in the d-nginx-charlesreid1 repository. From the docker-compose.yml file nginx volumes directive: - \"./d-nginx-charlesreid1/conf.d:/etc/nginx/conf.d:ro\" other nginx bind-mounted files \u00b6 The last remaining nginx file that is bind-mounted into the container is /etc/localtime , which ensures our webserver's timestamps match the host's. In the nginx volumes directive: - \"/etc/localtime:/etc/localtime:ro\" mysql \u00b6 The MySQL database container is used by MediaWiki and stores its data on disk in a data volume. Inside the conatiner all MySQL data lives at /var/lib/mysql This is mapped to a data volume, stormy_mysql_data . There is no custom configuration of the MySQL database at this time, but to add a custom config file, mount it in the container via bind-mounting by adding this to the volumes section of docker-compose.yml : - \"./d-mysql/krash.mysql.cnf:/etc/mysql/conf.d/krash.mysql.cnf\" mediawiki \u00b6 mediawiki data volume \u00b6 The MediaWiki container hosts all wiki files from /var/www/html (in the MediaWiki container). When the container is built from the Dockerfile, most of the customized MediaWiki files are copied into the data volume. These include: LocalSettings.php - MediaWiki config file skins/ directory extensions/ directory MediaWiki files are kept under version control in the d-mediawiki repo. The MediaWiki container uses a data volume called stormy_mw_data , which is mounted at /var/www/html inside the container. The docker-compose file takes care of creating the data volume. mediawiki bind-mounted files \u00b6 (TODO: ambiguous how skins dir is mounted; copying skins into container in Dockerfile, and bind-mounting bootstrap2 at runtime.) MediaWiki skins are kept under version control in the d-mediawiki repo. The Bootstrap2 MediaWiki skin is bind-mounted into the container at /var/www/html/skins/Bootstrap2/ . If you make changes to the skin or MediaWiki config files, update the MediaWiki docker image as follows: docker-compose build docker-compose down docker-compose up gitea \u00b6 gitea data volume \u00b6 gitea bind-mounted files \u00b6 python file server \u00b6 pyfiles directory \u00b6","title":"Volumes"},{"location":"Volumes/#volumes","text":"","title":"Volumes"},{"location":"Volumes/#persistent-data-volumes","text":"docker-compose volumes are mostly persistent, but they can be deleted relatively easily. When you're using docker-compose, volumes are persistent through both docker-compose stop and docker-compose down commands. The docker-compose down command will destroy everything including networks and mounted files, while docker-compose stop will just stop the containers. DANGER - DANGER - DANGER If you want to remove the volumes, use docker-compose down -v . docker-compose down -v # DANGER!!! To force removal of the volumes: docker-compose down -v -f # DANGER!!! To see the current list of docker volumes: docker volume ls You can also interact with the volumes individually this way. Run docker volume for help.","title":"Persistent Data Volumes"},{"location":"Volumes/#nginx","text":"The nginx service does not have any data volumes, but has several static files that are bind-mounted. Most importantly, nginx handles the SSL certificates for all subdomains.","title":"nginx"},{"location":"Volumes/#nginx-lets-encrypt-ssl-certificates","text":"Rather than fuss with getting the letsencrypt docker image working, we made SSL certs by hand. See git.charlesreid1.com/charlesreid1/certbot Certbot will put the SSL certificates into /etc/letsencrypt/live/example.com . We bind-mount the entire /etc/letsencrypt directory into the same location in the nginx container (see this volumes line in docker-compose.yml ): - \"/etc/letsencrypt:/etc/letsencrypt\" To renew certificates (every few months), just run the certbot script in the certbot repo.","title":"nginx + lets encrypt ssl certificates"},{"location":"Volumes/#nginx-static-content","text":"The main site hosted by nginx (charlesreid1.com) is served up from a directory of static content under version control. This static content is bind-mounted and lives on the host (no data volume is used for nginx). On the host, static site contents are stored at /www/ with a directory structure and corresponding permissions as follows: /www/ # <-- owned by regular user charlesreid1.blue/ # <-- owned by regular user charlesreid1.blue-src/ # <-- owned by regular user <pelican files> htdocs/ # <-- owned by www-data <web site static contents> charlesreid1.red/ # <-- owned by regular user charlesreid1.red-src/ # <-- owned by regular user <pelican files> htdocs/ # <-- owned by www-data <web site static contents> charlesreid1.com/ charlesreid1.com-src/ <pelican files> htdocs/ <web site static contents> ... Each domain has its own directory, in which there is a source directory (git repository containing pelican files) and an htdocs directory (git repository containing live hosted static content). These are mounted in the container at the same location. See the volumes section of the nginx container: - \"/www/charlesreid1.blue/htdocs:/www/charlesreid1.blue/htdocs:ro\" - \"/www/charlesreid1.red/htdocs:/www/charlesreid1.red/htdocs:ro\" - \"/www/charlesreid1.com/htdocs:/www/charlesreid1.com/htdocs:ro\" The source and htdocs directories are separate branches of the same repo. Each website has (TODO: will have) its own repository. The master branch contains the source code for that repository, mainly pelican files plus html/css/js. The pages branch contains the static content to be hosted by the nginx web server. Ownership makes dealing with this stuff a pain in the ass. The htdocs dir must be owned/updated by www-data , so you need to update the git repo contents as that user: sudo -H -u www-data git pull origin pages","title":"nginx static content"},{"location":"Volumes/#nginx-bind-mounted-files","text":"We bind-mount a directory conf.d containing nginx configuration files into the container at /etc/nginx/conf.d , which is where nginx automatically looks for and loads configuration files. The custom nginx configuration files are split up by protocol and subdomain, and can be found in the d-nginx-charlesreid1 repository. From the docker-compose.yml file nginx volumes directive: - \"./d-nginx-charlesreid1/conf.d:/etc/nginx/conf.d:ro\"","title":"nginx bind-mounted files"},{"location":"Volumes/#other-nginx-bind-mounted-files","text":"The last remaining nginx file that is bind-mounted into the container is /etc/localtime , which ensures our webserver's timestamps match the host's. In the nginx volumes directive: - \"/etc/localtime:/etc/localtime:ro\"","title":"other nginx bind-mounted files"},{"location":"Volumes/#mysql","text":"The MySQL database container is used by MediaWiki and stores its data on disk in a data volume. Inside the conatiner all MySQL data lives at /var/lib/mysql This is mapped to a data volume, stormy_mysql_data . There is no custom configuration of the MySQL database at this time, but to add a custom config file, mount it in the container via bind-mounting by adding this to the volumes section of docker-compose.yml : - \"./d-mysql/krash.mysql.cnf:/etc/mysql/conf.d/krash.mysql.cnf\"","title":"mysql"},{"location":"Volumes/#mediawiki","text":"","title":"mediawiki"},{"location":"Volumes/#mediawiki-data-volume","text":"The MediaWiki container hosts all wiki files from /var/www/html (in the MediaWiki container). When the container is built from the Dockerfile, most of the customized MediaWiki files are copied into the data volume. These include: LocalSettings.php - MediaWiki config file skins/ directory extensions/ directory MediaWiki files are kept under version control in the d-mediawiki repo. The MediaWiki container uses a data volume called stormy_mw_data , which is mounted at /var/www/html inside the container. The docker-compose file takes care of creating the data volume.","title":"mediawiki data volume"},{"location":"Volumes/#mediawiki-bind-mounted-files","text":"(TODO: ambiguous how skins dir is mounted; copying skins into container in Dockerfile, and bind-mounting bootstrap2 at runtime.) MediaWiki skins are kept under version control in the d-mediawiki repo. The Bootstrap2 MediaWiki skin is bind-mounted into the container at /var/www/html/skins/Bootstrap2/ . If you make changes to the skin or MediaWiki config files, update the MediaWiki docker image as follows: docker-compose build docker-compose down docker-compose up","title":"mediawiki bind-mounted files"},{"location":"Volumes/#gitea","text":"","title":"gitea"},{"location":"Volumes/#gitea-data-volume","text":"","title":"gitea data volume"},{"location":"Volumes/#gitea-bind-mounted-files","text":"","title":"gitea bind-mounted files"},{"location":"Volumes/#python-file-server","text":"","title":"python file server"},{"location":"Volumes/#pyfiles-directory","text":"","title":"pyfiles directory"}]}